{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvTranspose1D Test\n",
    "- https://medium.com/@santi.pdp/how-pytorch-transposed-convs1d-work-a7adac63c4a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, channel, length)\n",
    "x = torch.ones(1, 1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 1, kernel_size=(3,), stride=(1,), bias=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[1., 1., 1.]]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (out_channel, in_channel, kernel_size)\n",
    "conv.weight.data = torch.ones(1, 1, 3)\n",
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3., 3., 3., 3.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[1., 1., 1.]]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data = torch.ones(1, 1, 3)\n",
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 3., 3., 3., 3., 3., 2.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvTranspose1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, channel, length) \n",
    "y = torch.ones(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvTranspose1d(1, 1, kernel_size=(3,), stride=(1,), bias=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0571,  0.4288, -0.2723]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = deconv(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0571,  0.4288, -0.2723]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力の長さが長い場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(1, 1, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 3)\n",
    "x = deconv(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 2., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvTranspose1d(1, 1, kernel_size=(3,), stride=(2,), bias=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 2., 1., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride=2\n",
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=0, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 3)\n",
    "print(deconv)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride=3\n",
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=3, stride=3, padding=0, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 3)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 0., 1., 1., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride=4\n",
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=3, stride=4, padding=0, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 3)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride=4, kernel_size=4\n",
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=4, stride=4, padding=0, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 4)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 1., 1.]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride=4, kernel_size=8\n",
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=8, stride=4, padding=0, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 8)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 2., 2., 2., 2., 1., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride=4, kernel_size=8, padding=2\n",
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=8, stride=4, padding=2, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 8)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 1., 1., 0.]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=8, stride=4, padding=0, output_padding=1, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 8)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 2., 2., 2., 2., 1., 1., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(1, 1, 2)\n",
    "deconv = nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=8, stride=4, padding=2, output_padding=1, bias=False)\n",
    "deconv.weight.data = torch.ones(1, 1, 8)\n",
    "x = deconv(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
