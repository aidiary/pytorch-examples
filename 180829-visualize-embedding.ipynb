{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import tensorboardX\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./tensorboard')\n",
    "from mnist import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('tensorboard/mnist.pht'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124b10240>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = X[0][0]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Feature(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Feature, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            *list(model.features.children())\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 320)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST_Feature(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_feature = MNIST_Feature()\n",
    "extract_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 320])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_feature(X).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.zeros(0)\n",
    "labels = torch.zeros(0).long()\n",
    "label_imgs = torch.zeros(0)\n",
    "\n",
    "for batch_idx, (img, target) in enumerate(train_loader):\n",
    "    feature = extract_feature(img)\n",
    "    features = torch.cat((features, feature))\n",
    "    labels = torch.cat((labels, target))\n",
    "    label_imgs = torch.cat((label_imgs, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 320])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_imgs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorboardにEmbeddingを描画\n",
    "import tensorboardX\n",
    "writer = tensorboardX.SummaryWriter()\n",
    "writer.add_embedding(features[:1000], metadata=labels[:1000], label_img=label_imgs[:1000])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /Users/koichiro.mori/.torch/models/alexnet-owt-4df8aa71.pth\n",
      "100%|██████████| 244418560/244418560 [00:35<00:00, 6854938.63it/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dropout(p=0.5),\n",
       " Linear(in_features=9216, out_features=4096, bias=True),\n",
       " ReLU(inplace),\n",
       " Dropout(p=0.5),\n",
       " Linear(in_features=4096, out_features=4096, bias=True),\n",
       " ReLU(inplace)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.classifier.children())[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.5)\n",
       "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): Dropout(p=0.5)\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (5): ReLU(inplace)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "original_model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)),\n",
       " ReLU(inplace),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
       " ReLU(inplace),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace),\n",
       " Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(original_model.features.children())[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetConv4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetConv4, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            *list(original_model.features.children())[:-3]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNetConv4(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNetConv4()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
