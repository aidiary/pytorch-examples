{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tacotron2\n",
    "- https://github.com/NVIDIA/tacotron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2, Encoder, Decoder, Prenet, Attention\n",
    "from data_utils import TextMelLoader, TextMelCollate\n",
    "from utils import load_filepaths_and_text, load_wav_to_torch, get_mask_from_lengths\n",
    "from layers import TacotronSTFT, LinearNorm\n",
    "from text import text_to_sequence, sequence_to_text\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = create_hparams(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 500\n",
      "iters_per_checkpoint: 500\n",
      "seed: 1234\n",
      "dynamic_loss_scaling: True\n",
      "fp16_run: False\n",
      "distributed_run: False\n",
      "dist_backend: nccl\n",
      "dist_url: file://distributed.dpt\n",
      "cudnn_enabled: True\n",
      "cudnn_benchmark: False\n",
      "load_mel_from_disk: True\n",
      "training_files: filelists/ljs_audio_text_train_filelist.txt\n",
      "validation_files: filelists/ljs_audio_text_val_filelist.txt\n",
      "text_cleaners: ['english_cleaners']\n",
      "sort_by_length: False\n",
      "max_wav_value: 32768.0\n",
      "sampling_rate: 22050\n",
      "filter_length: 1024\n",
      "hop_length: 256\n",
      "win_length: 1024\n",
      "n_mel_channels: 80\n",
      "mel_fmin: 0.0\n",
      "mel_fmax: None\n",
      "n_symbols: 149\n",
      "symbols_embedding_dim: 512\n",
      "encoder_kernel_size: 5\n",
      "encoder_n_convolutions: 3\n",
      "encoder_embedding_dim: 512\n",
      "n_frames_per_step: 1\n",
      "decoder_rnn_dim: 1024\n",
      "prenet_dim: 256\n",
      "max_decoder_steps: 1000\n",
      "gate_threshold: 0.6\n",
      "attention_rnn_dim: 1024\n",
      "attention_dim: 128\n",
      "attention_location_n_filters: 32\n",
      "attention_location_kernel_size: 31\n",
      "postnet_embedding_dim: 512\n",
      "postnet_kernel_size: 5\n",
      "postnet_n_convolutions: 5\n",
      "use_saved_learning_rate: False\n",
      "learning_rate: 0.001\n",
      "weight_decay: 1e-06\n",
      "grad_clip_thresh: 1\n",
      "batch_size: 48\n",
      "mask_padding: False\n"
     ]
    }
   ],
   "source": [
    "for k, v in hparams.values().items():\n",
    "    print('%s: %s' % (k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:35: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n",
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "model = Tacotron2(hparams).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tacotron2(\n",
       "  (embedding): Embedding(149, 512)\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (prenet): Prenet(\n",
       "      (layers): ModuleList(\n",
       "        (0): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n",
       "        )\n",
       "        (1): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention_rnn): LSTMCell(1536, 1024)\n",
       "    (attention_layer): Attention(\n",
       "      (query_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
       "      )\n",
       "      (memory_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n",
       "      )\n",
       "      (v): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n",
       "      )\n",
       "      (location_layer): LocationLayer(\n",
       "        (location_conv): ConvNorm(\n",
       "          (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n",
       "        )\n",
       "        (location_dense): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_rnn): LSTMCell(768, 1024, bias=1)\n",
       "    (linear_projection): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n",
       "    )\n",
       "    (gate_layer): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (postnet): Postnet(\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "80\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(model.mask_padding)\n",
    "print(model.fp16_run)\n",
    "print(model.n_mel_channels)\n",
    "print(model.n_frames_per_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "print(hparams.n_symbols)\n",
    "print(hparams.symbols_embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(149, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(149, 512)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:35: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "512\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(hparams.encoder_n_convolutions)\n",
    "print(hparams.encoder_embedding_dim)\n",
    "print(hparams.encoder_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNorm(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1,\n",
    "                 padding=None, dilation=1, bias=True, w_init_gain='linear'):\n",
    "        super(ConvNorm, self).__init__()\n",
    "        if padding is None:\n",
    "            assert(kernel_size % 2 == 1)\n",
    "            padding = int(dilation * (kernel_size - 1) / 2)\n",
    "        \n",
    "        self.conv = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                    kernel_size=kernel_size, stride=stride,\n",
    "                                    padding=padding, dilation=dilation,\n",
    "                                    bias=bias)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain)\n",
    "        )\n",
    "    \n",
    "    def forward(self, signal):\n",
    "        conv_signal = self.conv(signal)\n",
    "        return conv_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutions = []\n",
    "for _ in range(3):\n",
    "    conv_layer = nn.Sequential(\n",
    "        ConvNorm(512, 512, kernel_size=5, stride=1, padding=2, dilation=1, w_init_gain='relu'),\n",
    "        nn.BatchNorm1d(512)\n",
    "    )\n",
    "    convolutions.append(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutions = nn.ModuleList(convolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Sequential(\n",
       "    (0): ConvNorm(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    )\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ConvNorm(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    )\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ConvNorm(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    )\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(512, 256, 1, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 256, batch_first=True, bidirectional=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filelists/ljs_audio_text_train_filelist.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TextMelLoader(hparams.training_files, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiopaths_and_text = load_filepaths_and_text(hparams.training_files, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['./LJSpeech-1.1/wavs/LJ037-0003.wav', 'Eyewitnesses'],\n",
       " ['./LJSpeech-1.1/wavs/LJ043-0159.wav', 'Answer: Yes.'],\n",
       " ['./LJSpeech-1.1/wavs/LJ006-0281.wav', 'in some yards'],\n",
       " ['./LJSpeech-1.1/wavs/LJ032-0100.wav', 'Marina Oswald'],\n",
       " ['./LJSpeech-1.1/wavs/LJ031-0024.wav', 'Gene C. Akin;'],\n",
       " ['./LJSpeech-1.1/wavs/LJ011-0028.wav', 'In his defense'],\n",
       " ['./LJSpeech-1.1/wavs/LJ012-0199.wav', 'After a little'],\n",
       " ['./LJSpeech-1.1/wavs/LJ037-0219.wav', \"Oswald's Jacket\"],\n",
       " ['./LJSpeech-1.1/wavs/LJ040-0062.wav', 'The Early Years'],\n",
       " ['./LJSpeech-1.1/wavs/LJ033-0135.wav', 'Location of Bag']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audiopaths_and_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['english_cleaners']\n",
      "32768.0\n",
      "22050\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(hparams.text_cleaners)\n",
    "print(hparams.max_wav_value)\n",
    "print(hparams.sampling_rate)\n",
    "print(hparams.load_mel_from_disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "256\n",
      "1024\n",
      "80\n",
      "22050\n",
      "0.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(hparams.filter_length)\n",
    "print(hparams.hop_length)\n",
    "print(hparams.win_length)\n",
    "print(hparams.n_mel_channels)\n",
    "print(hparams.sampling_rate)\n",
    "print(hparams.mel_fmin)\n",
    "print(hparams.mel_fmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = TacotronSTFT(1024, 256, 1024, 80, 22050, 0.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./LJSpeech-1.1/wavs/LJ037-0003.wav', 'Eyewitnesses']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "audiopaths_and_text[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./LJSpeech-1.1/wavs/LJ038-0003.wav\n",
      "Oswald's Arrest\n"
     ]
    }
   ],
   "source": [
    "audiopath, text = audiopaths_and_text[10][0], audiopaths_and_text[10][1]\n",
    "print(audiopath)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['english_cleaners']\n"
     ]
    }
   ],
   "source": [
    "print(hparams.text_cleaners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 46, 50, 28, 39, 31, 55, 46, 64, 28, 45, 45, 32, 46, 47, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = text_to_sequence(text, ['english_cleaners'])\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"oswald's arrest~\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sequence_to_text(seq)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `hparams.load_mel_from_disk` はTrueになっているがなぜ動く？音声ファイルが入力だからFalseにしないと動かないはず"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = load_wav_to_torch(audiopath, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12029b358>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4VOX1wPHvISHsOwER0AQIm6KIEQREEBBB2iJWW9RWWxesYi21rcUf7ittXVr3uiDYBVRaFQVUFEUFWULZ9wBBIrthlTXJ+/tjbnBCZjLb3WZyPs+TJzPv3Ln3zGRyz9x3FWMMSimlVCyqeR2AUkqp5KPJQymlVMw0eSillIqZJg+llFIx0+ShlFIqZpo8lFJKxUyTh1JKqZhp8lBKKRUzTR5KKaVilu51AE5p2rSpycrK8joMpZRKKosWLdptjMmMtF3KJo+srCzy8vK8DkMppZKKiGyOZjuttlJKKRUzTR5KKaVipslDKaVUzDR5KKWUipkmD6WUUjHT5KGUUipmmjyUUkrFTJOHg2at2cHWvYe9DkMppWynycNB10/Io9e4WSwsKPI6FKWUspUmDxe8NmeT1yEopZStNHkopZSKmSYPh0xZVOh1CEop5RhNHg75/VtLvQ5BKaUco8lDKaVUzDR5uGD68u1eh6CUUrbS5GGz/J0HyRozrUL5os3aXVcplTo0edjs9kmLQ5YfOlbiciRKKeUcTR5KKaVipslDKaVUzDR5KKWUipkmDxuVlBpWbdsf8rGd+4+6HI1SSjlHk4eN3srbEvax3+mgQaVUCrEleYjIeBHZKSIrgsruF5FvRGSJ9XNp0GN3iUi+iKwVkUuCygdbZfkiMiaoPFtE5ovIehF5Q0Qy7Ijbbku27PU6BKWUcoVdVx4TgMEhyp8yxnS1fqYDiEhnYARwhvWc50UkTUTSgOeAIUBn4CprW4A/WfvKAfYAN9gUt22OHC9h8sLwVx5KKZVKbEkexpjPgWhHwQ0DJhtjjhpjNgH5QHfrJ98Ys9EYcwyYDAwTEQH6A1Os508ELrMjbjsVlxqvQ1BKKdc43eZxm4gss6q1GlllLYHgr+iFVlm48ibAXmNM8UnlSeftxTrTrlIqNTiZPF4A2gJdgW3AE1a5hNjWxFFegYiMFJE8EcnbtWtX7BE77LdvLOWxGau9DkMppRLmWPIwxuwwxpQYY0qBlwlUS0HgyqF10KatgK2VlO8GGopI+knloY75kjEm1xiTm5mZad+LicLQp7+Iaru/z97ocCRKKeU8x5KHiLQIujscKOuJNRUYISI1RCQbyAEWAAuBHKtnVQaBRvWpxhgDfApcYT3/OuBdp+KOx6bd37H520Neh6GUUq5Jj7xJZCIyCegHNBWRQuA+oJ+IdCVQxVQA3AxgjFkpIm8Cq4BiYJQxpsTaz23Ah0AaMN4Ys9I6xB+BySLyMLAYeNWOuO1y0eOfeR2CUkq5ypbkYYy5KkRx2BO8MeYR4JEQ5dOB6SHKN/J9tZdSSimP6QjzBBXuib26KlATp5RSyUuTRxz+8VUB7yz+BoCfvPhVzM9/bU6BvQEppZTLbKm2qgpKSw0zVmxnYUERE+YWADD6jSVx7StvcxHXX5BtY3RKKeUuTR5RmjC3gAffX+V1GEop5QtabRWl9TsP2ravgt3arVcpldw0eXhg1bb9bNr9nddhKKVU3DR5eGTH/iNeh6CUUnHT5KGUUipmmjyiJKGmZ1RKqSpKk0eU7B7Xp+MElVLJTJOHUkqpmGnyiMKhY8VMWvC1rfu86uV5tu5PKaXcpMkjCos273Fkv+8t3crOA9rrSimVfDR5eOjXkxZz7asLvA5DKaVipsnDY2u2HyCvoMjrMJQCoKTUUFxS6nUYKglo8vCBuRu+9ToEpQAY/vwc2o2d4XUYKglo8khhCwuKOPehmew/ctzrUFSSWFa4z+sQVJLQ5JHCnpq5jm+/O8ZyPSEopWymycMHdMCgUirZaPJQSikVM00eSimlYqbJIwpCcs6KqNVhKhF5BUXMyd/tdRjKp3QZ2iogOVOf8toVL34FQMG4oR5HovxIrzyiYNCv8Kpq0ZUuVSS2JA8RGS8iO0VkRVBZYxGZKSLrrd+NrHIRkadFJF9ElolIt6DnXGdtv15ErgsqP1dEllvPeVpEV9dQyi6Lv95D1phprNq6/0TZRY9/5l1AKinYdeUxARh8UtkY4BNjTA7wiXUfYAiQY/2MBF6AQLIB7gN6AN2B+8oSjrXNyKDnnXyspLZ9/2GvQ1BV2AcrtwMwe90ujyNRycSW5GGM+Rw4eYKmYcBE6/ZE4LKg8tdNwDygoYi0AC4BZhpjiowxe4CZwGDrsfrGmK+MMQZ4PWhfrnC6wXzSgi0cK7Z/PiGtblN2GPTUbMdmllbJy8k2j+bGmG0A1u9mVnlLYEvQdoVWWWXlhSHKU0pxaSklpQ6d7LWST0Uh3JeNdTsO8uj01S5Ho/zOiwbzUKcyE0d5xR2LjBSRPBHJ27XLvktwN77Bb9z1HW3/bzrTlm2zbZ/f7NXqMKWUM5xMHjusKies3zut8kKgddB2rYCtEcpbhSivwBjzkjEm1xiTm5mZacuLcMvybwLzT5XVP9thS5EmDxW9yqpn9eJVnczJ5DEVKOsxdR3wblD5tVavq/OBfVa11ofAIBFpZDWUDwI+tB47ICLnW72srg3alyvcGCT4xsItkTdSykHaRqZiYVdX3UnAV0AHESkUkRuAccDFIrIeuNi6DzAd2AjkAy8DtwIYY4qAh4CF1s+DVhnALcAr1nM2ACm34MCSLXsB2KXL0qogR46XcP/UlRzQafWVz9gywtwYc1WYhwaE2NYAo8LsZzwwPkR5HnBmIjEmi3kbi9ix/wjN69e0bZ/JOr2Kgn/O28yEuQXUrJ7GmCEdHT1W/s6Dju5fpRYdYe5Duw4cTXgfew8dsyES5bWyHnilLkxU9t//fRP2MR2Wq06mySNF/XrSYq9DUEqlME0eKeqbPdrTSinlHE0eKWpj0MR2i7fo6GCllL00eVQBT3y0zusQlI9F06FCO12ok+l6Hkr5UGmpoeBbd6ZF1/EdKh6aPJTyoadnreevH6+nelrgG7/xellIvfBQJ9FqKx+avW4X7yz+hoNHi23Zn+cnHhWzvIJAO9XxEuf/dlolpeKhVx4+9JcP1564nXf3QJrWrZHQ/pyarFe553iJwRiDE+ugabWViodeefjcv+d/7XUIygcmzC3gH/M2e3b8LUWHuH/qSkr1m4iyaPKIgpeja5+cmXo9pTbsOsic/N0sL9zHseJSjpeUXwhr3Y4DFcoU3PvuSp78aG3kDWMUTbXVtn1HmDC3gBVb99l+fJWctNoqBfm9jWPAE7MrlBWMGwpA4Z5DDHrqc4ae1YKRfdpwduuGFJeU8t2xEhrUqu52qK4zxlS6KNjfP9/IHYM6uBhRedo+osrolUcUfH4ujsq2fckx4nzPd4HZY6ct28aw5+YAMPbtFZz9wEcUl5Sy++BRJszZ5PsEGa8H3ltFu7Ezws5llZqvWiUjTR5JoNiGKpwhf/vChkjcN2vNDt7IC6x1UmIMt09azP3vrWLdjtScAfb1rwqA1PjColKbJo8oeD2jaL/HP0t4H3sP+X89iE/X7GT8nE3lyq6fkHfi9pj/LGfuhm8BtE1ExcwYo58bG2mbRxIojGGSwymLCllWuNfBaOJnjOH5zzaEfGzr3sP8csLCSp//9uLwU4YrFcnzn23gLx+uZem9g2hQO/Xbz5ymVx4p5vdvLeX1r7zr0lmZTbu/KzeGJVivcbNcjsbf3Bp78eTMdbw4O3RCT0Z/+3g95z40M+RjZZ+9XQcTXy9HafKIih/qnzfsSv46fjcWNEp1x4pL2WjjZ+G1LzdF3iiJPPXxOr79ThdCc4MmjyTx81fmex2Cryz+eg+bdrszcaAXKsuz/UN0dY5blex5q19i7KDJIwpeN5gDHNeRveXc8+5KLnr8M+57dwXHirURVJX3xEdryRozjbn5u0M+ftPreUxeoLM3JEKTR4o4VlzKPh/1qFq7/YCt1SvhTPxqM/+ev5n9R/zz2u0wf1ORK8fxwfciRzwzKx+Aq8Ncsc9ctYMx/13O3e8sZ8RLX7kZWsrQ3lZJItI/+c3/yOPTtbtciSUal/z1c+D7keMBzpyq7n9vFfe/t4qrup/GL3plUbN6NU5vUseRY6UaJyZa9LvgKsF/ztOrj3hp8kgSOw8crXRWVT8lDq9MWvA1k6yqiPJJS4UTa+6ogrlGhaHVVklk1L//53UIUTkQogpp9bb9OkOwjVZ8Y88EhbHmgu37jrB2+wFbjh2r4pLSuKal2bDrIFljpjkQUdXmePIQkQIRWS4iS0QkzyprLCIzRWS99buRVS4i8rSI5IvIMhHpFrSf66zt14vIdU7H7UfTl29P6PlTFhXy3tKtNkUTWuGeQ3S5/6NyZVljpjHkb19UGD3upCc+Wsu+w6nVDhLsB898mfA+Fm3ew54Y28lufD3vRJWkmw4eLabd2Bk89fH6mJ/7/tJtDkSk3LryuMgY09UYk2vdHwN8YozJAT6x7gMMAXKsn5HACxBINsB9QA+gO3BfWcJR0fv9W0v59aTFjh7j66JD5e6f98jHjh4vnGdm5fPItFWeHDtZ/PiFuV6HELVnZgWSxtOfxJ48lmzZU+5+qGuX1+ZsOnHFvGhzEX+LI0lVNV5VWw0DJlq3JwKXBZW/bgLmAQ1FpAVwCTDTGFNkjNkDzAQGux20X+3x8aCoXQe8G817VLvwpoyd++P/HO0/Un4556PHK34uHnhvFXdOWQbAj1/4iqc+Tr11dOzmRvIwwEciskhERlplzY0x2wCs382s8pbAlqDnFlpl4coVRJwTylU6HKVKmDi3gP99Xf4b/aLNRSHbuxK1cdfBcvO1HTpWXO72FS/MZd2O8O0wizaXj/PpWaGvKmasSKxauKpxI3n0NsZ0I1AlNUpELqxk21Dtd6aS8vJPFhkpInkikrdrV2r2PgrVYLhhZ/JPXeIEnQ3FOfdNXcnlzweqvb47WsyWokP8+IWvuPkfi2w/Vv8nZrNh1/ezCXyz5zCjJy8ma8w05m38lrzNe3hs+uqo9zdz1Y6otssaM41/erj0r985njyMMVut3zuBtwm0WeywqqOwfu+0Ni8EWgc9vRWwtZLyk4/1kjEm1xiTm5mZafdL8YWnP8mvUHa8VKtnnLRuxwGyxkzjy/WB0crHiuPr9WO3d3wwy/CR4yVc+vQX9Pnzp4B9vcAieWdJ+X///F0HeTzMpJuJuPudFbbvM1U4mjxEpI6I1Cu7DQwCVgBTgbIeU9cB71q3pwLXWr2uzgf2WdVaHwKDRKSR1VA+yCpzxfU+qhYKVRd7JEQdrhf2HT5+Yr0NPyjcc8iWCSUXWKO9py3fxtuLC2l/9wz+4YNvpKPfWOJ5F9SO93zA5m+/7yThxqDDUDP1bCk6zLOfVvxiFav5G/3z+fU7p688mgNfishSYAEwzRjzATAOuFhE1gMXW/cBpgMbgXzgZeBWAGNMEfAQsND6edAqc4U2vEbnln8usuUf2C7/+3pvyPXSY/X9+dDw2zeWAjB1ibNdnp2UNWYad05Z6nUYcVvq4Ho1P31pXoUyO1byTEWOjjA3xmwEzg5R/i0wIES5AUaF2dd4YLzdMSp7/Gv+Zl9dddhJrCY3p5e+3VJ0KOS3aie8mVfo6P6zxkzj1/3b8btBHRw9jhu1h95XUPqTjjBXCft0zU7Gvu3fuuG+f/mUb/ZGvxrjycq6Gwf32qnmQPXM8Ofn2L5PtwW/LWWTE6rUpMlDJWTR5iJ/dRUOYfO3h3grb0vkDcM4fLykQtmCAvtrTXcfjG+8jh8a71XVo8lDJeTbOE94bvvrx+vj7vjg92Va/ZQ7XJk30eXXu33fEXcPmCQ0eagqY9aanZE3ikHhnkO8OHuD59/8j8XQoJvnwBWT2/784ZoTt91462/9V3JMSOo2TR4qbuO/3MRIBwaFJYuBT85m3Iw1CbWn2KHjPR+wbV/kGA4fK+GKF51d+EhEyiXTZ2etjyu5Hi8p5WevzK8wih3ir96L13KXxq4kG00eKm4Pvl+1Jx4sG1/jh2qjufmRe7oVuzSYNPj9ePyjdew8cJR3l3xD1phpUU9fUrD7O77M381vJlc+keeR4ortUcodmjyS0MS5BV6HoILcMNH7DgO/e2spH/hgbiahYpPEtGXb+IM16eDJsy5HsqWo8iuqr1K0e3gy0OSRhO6buvLE7RK3BgakiFVb99u+T7vGfyTa+3dZJYPn9h85Ts/HZiV2gCidXE314PurOFYc21VatJ/qf+kCY57R5JHk4lnfwA479idnD5RLn/6i0pNsqlr89V4OHi2OvKENKjvxl0aZPdyaIytaXneK8CNNHkmqpNRw6FhxyAbFSOw4efZ49JOE9+GVbTF0vRwdoc7dT/xwejt0rISFlfToivZC+cOV3lfBBSvc422nCD9ydHqSVLBp93eRN/JA1wc+4kCc3yR/9OwcCsYNtTmi5BHL6PCTZ2/1Mz98OT58vISrX54f9vEjx0s4VlxKRnrl31s/XBndtOnKO3rlEcHAJxOfWM8J8SYO5dJAtjgkGteR4yUVqlcWFhTR49GPOeSTz8uIl+Z5tjRxIlyYLDjp6JVHBKnaIL28cB9dWjXwOgxPVPPpV6ZEP2oT5haQWa8Goy5qx/1TV7KwoIg6NdLZsf8ot/hooNu+w/avNqjc59N/I3/Y78CSmn6xYqu/GiTd5MaaE155cfYGDhw5zoS5Bazcup+jIeblUrFb8Y39vfSSnSaPSvS1VkdLRYmcPvceSo75rMJJizJ5fBdDVU/ZzLteO3CkmC73f3Ti/tLC5PuS8PW3sY0FccOv/ll1Z1IIR5NHJfYcSt0rj3hrSFZt3U/XB2faGovbom0wP3Qs+m/tqTBnlF9c+JfU/dKWSjR5VFHPxDE+5MjxEqYv3+ZANO762avzeeC9lZE3VCoBxpgTgyNTkSaPKmprHNNM+22Z2US8Nqcg4jbGFyMnqpZU6qDywHuraH/3jJR6TcE0eVRhsY6a/XTtLoci8ZefvPgVt09ybnDgxl0HWbNdG2BDiXbixGQwwZqD7rU5m1i7/YC3wThAk0cVln3XdK9D8KUFBUVMXbqV2TEky2iv5I4cL6H/E7MZ/NcvuH9q1a06G/r0F+wMMcVN/k5n14n3wsPTVnPJXz9PuSosTR5V3OEYGoWrmrKZYKPx0Pur+PZg5T2utu87Qsd7Pjhxf0LQ7MjJOldYvFZu3c8bCysuDez0eiOJWJ5gz7X2d89IqTmyNHlUcZe/MDelPtCxyBozzdZux+c+XPnI6crmFPNLV18v+b3K6ofPfsnc/N0J7eNoCl19aPKo4lZv20/2XdM5EmEwWWmKNvoVuDimINSqi3+fvYHjJaW+mJfKbTsOHGHPd98n7+DxKX519Svh5+2KxkoHlgTwiiYPBcDVL8+jcM+hsEnih89+6XJE7hj1r//x4uwNtu0vf+cBejz6MTsPlK+GCjdbwWMz1pAzdgaPzVhtWwzJ4p/zvuach2bGNBjTD+767zK2xLioVZkfvzDX5mi8I6laZZGbm2vy8vIS2kfWmGk2RZNc7v1BZwzwwmf5/P3n5/LGwi28mVfodViOEoFNjwVmGrbj7/7I8DO5psfpJ+5X1c9SKrvvh535Ze/ssI+H+5vnPzKE9DT/fm8XkUXGmNyI2yVL8hCRwcDfgDTgFWPMuMq21+ShYnXDBdlc0+M0+j9h30zKd1zcnidnrrNtf8qfbunXlsPHSrjr0o7USE/jiY/W8sys8GOinrnqHDq1qEe7ZvVcjDI6KZU8RCQNWAdcDBQCC4GrjDGrwj1Hk4dSKhnM+E0f9h0+TkZ6NZrUyWDi3M3c2CebFg1qYkxgKqFqAsWlhnU7DnDGqYHZsI0xISf5DFcerWiTR7JMyd4dyDfGbAQQkcnAMCBs8ojXjOXbfDV9tVIqtQ352xcVysbP2ZTQPl/8WTcGn9kioX1E4t+Kt/JaAsGdwgutsnJEZKSI5IlI3q5d8Y2GnrVmZ3wRKqWUT5zepI7jx0iWK49Q12AV6tuMMS8BL0Gg2iqeA/35irN4ePiZHDleytkP+L/roFIq9Q3s1IyPV+8ks14N7rykA899mk920zo0qVuDzi3q065ZXQr3HKZ141r0btuUatWcX7MmWZJHIdA66H4rwJHFpUWEGulpVPfrcnNKKV+64YJsDh8v4d/zv476OW/f2ovOp9anRnpaTMe6Mrd15I0clizJYyGQIyLZwDfACOBqJw/oRuZOBmMv7cQj06vOGIQzTq1vy0CuT3/fj217D9OrXVO27j1Mr3GzbIhO+U2otoVHh3cBKu9wUzBuqKNxuSEpkocxplhEbgM+JNBVd7wxpurOKuewRXcPpFHtjBMJ9KYL21SZnmfTbu+T0GuddNP5lBpDdtM6ZDcN1Duf2rAWt/Rrywuf2TcYMdUM7dKCaUmyVkzHU+ox4rzW/KKSMR6VSYXEAcnTYI4xZroxpr0xpq0x5hGv40k1v+rblpYNa9GpRX2a1K1R4cqrdkZsl9XJpNtpDWlYuzo3XhDfySBYz7ZN6N2uaYXy3w5sH3L7C9o15b+39uKdUb0TPnayeuzyLjx3TTevw4jaGyN7RpU4alZPmtNrXJLiykM56/8u7cjIC9syZkjHsNv8JLd1uVlgU8l/b7XnxN2/Y7Owj2WkV2Pdw0Nof/eMcuWvX9+datXEsckpm9bNYPdB/6453755XS454xQARg/M4a8fx77CpZsu6pBJg9rVo9p2yq968YNnyk/rs/rBwU6E5YnUTo0qKl1bN4q4zYBO4U+MKmD8L86r9PGM9Ir/bmVXeIkM6gql22kN+eR3fZnwy+4AXNX9NFv3b5ePftuXxnUyAGhYK7qTslfGXd6F16z3MxpntmzAsvsHlSurlUJX8Jo8FDnN6kbcpk9OJn++4iwXonFX73ZNKpRtfPRS8h8ZEtN+ru4R3cn5eReqZx740Rn899betM2sy5ktG/DKtbnc98POjh83Fjf3bcObN/csV/bznlneBBOlEXEk4Po1q7Nw7EA++30/1sf4mfI7TR5V2L9u7MH6R4bQyPrmV9UsGDuAV6+reLVQrZqQnlaNP/24S9T7qhHiqiKUS7u0YMIvA8es8K20uj3fSq/rlVXu/sDOzalp077tMmZwR7pnNy5XllZNuLlvG48ick5mvRpkNa1DdR9PhhiP1Ho1Kmq/6JVF73ZNY/pAJ8M8aNE4pX5N1jw0mGb1alZ6Uk2PYaxPvw7RV+v169CMgnFDqV+zfDXN4DNPiXof8WgYZV290wrGDQ1bTXeDDZ0WlDs0eVRRrRrVivk5Z7Vq6EAk7kurJlF9E+/RpnHEbcpcmFOxh5XfLLl3UOSNHPTo8C58cedFlW4jISeT8F6o9qqqTt8RFbVOLeqnXL1tZWJpxLajwduO0+aM3/SxYS/OuLrHabRuXNvrMOKTGhfdttLkoWKSCvW20dZG1a/pck92G7JHpxb1E99JghIZBFenhr/aZspU1o29qkr+M0EV1rJh7FVPKnr1alanad0arh3Pr1U2bqqdkc7/7rnY6zAqaFrPvc9BstDkUYkBlQz68sodF38/UrleAt+MO5zivxXM3BLLSdrNLq5uTKeWDHX3jX3Y+8+unnCpxP+fJA+9+ovzXP3mGY32zetxyRnNgUDDb7z65GTaFVLSiaV54gdnObugTjA3qtWX3eduo/mCsQNcPZ5TLggx5UxVp8kjyVQTuHNwoP41q2l8C74kcsWSCmJJuXaP/HbS8HMqrI9WgdvjPZrVq8lPc1vz8/NPj+l5fXzWey2VRobbpWqfRZLQ6U3q0DazLq9cm0vPtk2Ytiz2mUi1rST1tGtWl8evPNvrMEL6UxwzEwzt0oIv1u92IBplF00eSeT2ATkn2ioGdm7ucTTJK5muJqJVOyMtoWpMv0nBP1HK0WqrJDF6YE65xvJEJDpQfPTAHFvi8Eo8AyQrM/1278dW+G3w/zmnNWTEeYmvdveT3FY2RKOcoMkjIn/8V2bH2b7hhNFh1qZIBi9c041nr7J3csLOp3o/tsL45HNa5u1bezPux/FPpHlKg0CCz25al0eGn2lXWMpGWm0VQe2MdMC/6yHEo24VbjAf0sW93lNu6tra+6ljHru8i21dwPu2z+TfN/WgR3YTVm9LfFngRGTqGI+Qqu5ZJEr/uKE7f5iyjAWbijyNw85eMi/YMC34O6N6M3ryYgq+PWRDRM66fUAOHZrXc2QcxeXdIvdwclrf9pnc+4MzPDt+68a1eOnnubaPbu/VNtDjqnUjb6c0SaGmJFtptVUEpzepw8vX5nodBhd3sq+BvFn9mgnvo2vrhoy8sK0N0Tjvpj7ZDD2rhe1XHasfHMyTP+lq2/7iPUd1PrW+p4P/aldPd3RalAa1q9vW3qfso8kjCfRs06TCmuJ+0KSu/0YChxLL1OqxsLvvf7ytFv77ZDjrj4M7RpydVzlPk4ePlXVXPKtVA28DCWNQ5+a2VIE56bmru6XsAK9zTw8sH3xxFeu2/au+bVydnddvPdn8Qts8fOrOwR24tV87lhfuo1MLf85DJSK+b4Ae6uL0Ion66XmtmbKoMOrtp/yqZ1xjVvq2z2T2ul0xPy9Y8/o12LH/aEL7iEXwCbzsNf/nll48/2k+n6zZ6eyxHd178tIrj2h4+Onp0qoB6TZOg55KA8lSzXlZjbmqe3RjIx740RlxD3aceH13/vrTxNpqZv/hImb9ri/g3USG557eiJEXOr9s7e+0vSUkTR4+1aJB4o3ablly78UpufZ0KH6Zc+nkdcpjddk5LTnntMS697bJrMtjl3fh2avPSWg/0Qg3jsWN73WNfDjLrx84ljxE5H4R+UZEllg/lwY9dpeI5IvIWhG5JKh8sFWWLyJjgsqzRWS+iKwXkTdEJKX/mue3acxlXZ3pAurEOuQNa2dw15BOPPAj77qLOqmOB20mPds0cfwYdnwUrup+Gk18MPO0k729tM0jNKevPJ4yxnS1fqYDiEhnYARwBjAYeF5E0kQkDXgOGAJ0Bq6ytgX4k7WvHGAPcIPoq5zSAAAQNElEQVTDcZfj9ujd/h2bJeX8S6Uh/ssSWVXOL4Kr+hrVDnxvue2ido4cq+wtTMI/v6Nqh0ngZe9XXQdXIKxZXStoQvHiXRkGTDbGHDXGbALyge7WT74xZqMx5hgwGRgmgbNof2CK9fyJwGUexK0i+NHZp9IxxAjjBWMHsPTeQa4nEruad4IT+cPDz+TBYWfwu0He1YPbdYWXTAnqF72yK328mk0vJtRn9HwXrgKTkdPJ4zYRWSYi40WkkVXWEtgStE2hVRauvAmw1xhTfFJ5BSIyUkTyRCRv167EepOo2DWpW4MPRl9Y4R+wWb2aNKhd3dVYbu/fjqm3XWDLvoLPS/VrVufanlmOXRmW7bayqpJE2zuSUUZ6Ne4e2on3fx3+b3rn4A6OHNvtNVCSRULJQ0Q+FpEVIX6GAS8AbYGuwDbgibKnhdiViaO8YqExLxljco0xuZmZ9q2U58ba0i9fm8uNF2S7drxUd8egDpzZ0p7xMW7+NSLVr9/azx+j+u36ph+LG/u0qfA3Da5SvrVf6KrERlF+cWkSomG8b/uqu+JmJAmN8zDGDIxmOxF5GXjfulsIBPdHbAVstW6HKt8NNBSRdOvqI3h7V7jV5nHZOS155ctN9O/k3NrpVaHt79HhXWzdn1/an5rXr3FiFUkvvf/rC3y3Fnplf6LLzmnJa3MKIu7jXzf1KHc/FdrrnORkb6vg0VnDgRXW7anACBGpISLZQA6wAFgI5Fg9qzIINKpPNYHuQZ8CV1jPvw5416m4vSLAmS0bUDBuKG0z63odTsL+c0sv16fSvuGCbD767YVc3eM0W/dbtvJi9TT3kkhXqxtt8Gy5H43u68ixnrs6tlkC7Lqis0Om1dOrixXTz86P729fMG4oHU8J9Ni68lxdQyQaTn59+LOILBeRZcBFwG8BjDErgTeBVcAHwChjTIl1VXEb8CGwGnjT2hbgj8AdIpJPoA3kVQfj9kSqXRGce3ojrukR27rVibrnB51p39z+0fjXWMnIqe7TwUYPbM9FHTK5tV9bCsYNZfLI84FAnb/d7UZ1MgIVD8k8cDSneT3eu+0C/mhdkd3/wzOYd9eAqJ8farr1v1x5tl51RMGx6UmMMT+v5LFHgEdClE8Hpoco30igN5YntJ931eZm/f4pDWry2i/d+ag/+dOzeXPhFs5uHf2VxKiL/NHmEqxL0Nxv6WnVOCXCANs/XNKBv3y4FoA5f+xPSan+g8fDXxWXVVi8p6d6Nb7P/++M6m1PMA5yoq68dkYadw/tZPt+U12zejW5rX9OTF+OvGgoT9SPzj613P1RQWN0MtKrpezEmU7T5OET8X73SQuqh2/fPHJbiddXUeseHhJ175do9W7XlBv7pOb0KOlWldJwB6vMYvlI1M5IvrlUO5xST6uhHKDJIwp+vqgt695blTV1eF2RS89qwYXtMxntwQR56WnVWHrfIF+s4/1/l3bkBv28KYsmD5+ItzLgtv451EqyQUzhknFGejUKxg2NqQrq0eFduOcHnSNvmIC6NdJ5/fruJ3pdua1Breq2zqx8smjnOxt5YVvfddGNxYjzWoecAUHFJ/muQT2QfLW8/hbpXHVjnzZMWVTImu0Hwm7TsmEtru15uu3dcquiaHKH01d3bhj347O8DiGlaPKIghvVVpF6iNgl3ARzfhCcpEOd0B6+7EzWbN/PP+d9zYjzWnNzX//1/ElFk246nzaZdbwOI27J2MifDDR5+ECDWtVdGXg19tJO9Ovgz+kWmtWLPHq6ad0MmtQJ9MtPc3HAXlXXs23yTQzYqHZ1zjmtEdf3zg45N1XD2tW59nx3xyGlGk0ePuDWMrM3ubDqWjRC1bEvGFt+pptLzmjO2h0Vq61u7tuGA0eK+WWEWVZV9LzugeeExfcOqvTxJREeV5Elb+uXi5xYQMkpH9/Rl5m/vdDrMCr1m4GBXkvrHh4SdpvRA9uz+J6Ly5XVykindkY69/6ws/bNt5Hb69Wo1KDJI8W0a1aXHAem6LDTDRdkUzBuKBnp1RjQMfQkkNWqSbnlPx8adgYX+mQJWKWUVlt5qn7NdPYfKY68YQp77ppuFH13LOzjU2/rTeM6GbRqVNvFqKqWJLqwVj6iVx5RcOp/68WfnQtwYjbPqqhm9TROrWT8xFmtGmricJjmDhUPvfLwUIdT6vHWr3pydquGkTdWyiHJ1Kan/EOvPKLgVKfQujXTOS+rcVKP2lWp6flrYlvjQ1U9etbyyO0DcqiRrj2GlPdCXXcM6NSM+jW1YkKFp5+OKOhFvUploWqtjIGZd/RlS9Eh9wNSSUGTh1IqpOb1a9K8vjvT5qjko9VWHjkvq5HXIShlqXjpodNBqUg0eUTB7s4o1QT65PhzjilV9WhnKxUPTR4eqF/L3pX0xlrrX2gDvIqH5g4VD00eHrD7quNn559OwbihpFWrWNdw+4AcW4+lUk+dGhWbPkVXsVERaPKIQp0a9n2jf3dUbx6/0r1Fae7wYOlUlVxaNqzFv2/q4XUYKslo8ohC7Yx0xgypfK2JaJ3duqFWLynf6dW2KV/+8SKvw1BJRJNHlOrZMGBK/zmVn7VqVJvqusiWilJCyUNErhSRlSJSKiK5Jz12l4jki8haEbkkqHywVZYvImOCyrNFZL6IrBeRN0QkwyqvYd3Ptx7PSiTmquLanrpKmoqd9rxS0Ur0ymMFcDnweXChiHQGRgBnAIOB50UkTUTSgOeAIUBn4CprW4A/AU8ZY3KAPcANVvkNwB5jTDvgKWs7FcGDw86kYNxQr8NQSUrHeahIEkoexpjVxpi1IR4aBkw2xhw1xmwC8oHu1k++MWajMeYYMBkYJiIC9AemWM+fCFwWtK+J1u0pwABr+6TTqHZG5I2UUioJODU9SUtgXtD9QqsMYMtJ5T2AJsBeY0xxiO1blj3HGFMsIvus7XeffFARGQmMBDjttNNseSFlsprUSej5t/RrG7JLpBu+uPMiSkq1PkJF1u20RiwoKNKOuiqiiGczEfkYOCXEQ2ONMe+Ge1qIMkPoKx1TyfaV7atioTEvAS8B5Obm2nq27N2uKTN+04chf/vCzt26onVjXUxJRefVX+RSsPsQ6Wnal0ZVLmLyMMYMjGO/hUDroPutgK3W7VDlu4GGIpJuXX0Eb1+2r0IRSQcaAEVxxJSwTi2q7op/qmqoV7M6XVo18DoMlQSc+noxFRhh9ZTKBnKABcBCIMfqWZVBoFF9qgksZfYpcIX1/OuAd4P2dZ11+wpglvFw6bOnfnq2V4dWSinfSLSr7nARKQR6AtNE5EMAY8xK4E1gFfABMMoYU2JdVdwGfAisBt60tgX4I3CHiOQTaNN41Sp/FWhild8BnOje64Xh57TilWtzI2+olFIpLKEWXGPM28DbYR57BHgkRPl0YHqI8o0EemOdXH4EuDKROO02sHPzmJ9T16PGcqWUcoK2isXppZ+fG9P2N/Vp41AkSinlPk0ecerXoVnU2zatm0FGur7VSqnUoWe0OGWkV9MpQJRSVZYmjwSc2VK7NCqlqiZNHgk4L6ux1yEopZQnNHkkILtpHQrGDWVolxZeh6KUUq7S5GGDp686h9UPDj5x/5T6NT2MRimlnKfJwwZp1YRaGd+vDjj7zn7lHv97jN16lVLK7zR52OjKc1vx5E/OpkZ6GjN+0+dE+bmna9uIUiq16LBnG/3lyu/nverUoj5P/uRsWjSo5WFESinlDE0eDrq8WyuvQ1BKKUdotZVSSqmYafJQSikVM00eSimlYqbJQymlVMw0eSillIqZJg+llFIx0+ShlFIqZpo8lFJKxUyMMV7H4AgR2QVsjvPpTYHdNobjFo3bXRq3e5IxZkjOuE83xmRG2ihlk0ciRCTPGJPrdRyx0rjdpXG7JxljhuSNOxpabaWUUipmmjyUUkrFTJNHaC95HUCcNG53adzuScaYIXnjjkjbPJRSSsVMrzyUUkrFTJPHSURksIisFZF8ERnjg3gKRGS5iCwRkTyrrLGIzBSR9dbvRla5iMjTVuzLRKRb0H6us7ZfLyLXORDneBHZKSIrgspsi1NEzrXeh3zrueJg3PeLyDfWe75ERC4NeuwuK4a1InJJUHnIz42IZIvIfOv1vCEiGTbF3VpEPhWR1SKyUkR+Y5X79j2vJGZfv98iUlNEFojIUivuByo7lojUsO7nW49nxft6fM0Yoz/WD5AGbADaABnAUqCzxzEVAE1PKvszMMa6PQb4k3X7UmAGIMD5wHyrvDGw0frdyLrdyOY4LwS6ASuciBNYAPS0njMDGOJg3PcDvw+xbWfrM1EDyLY+K2mVfW6AN4ER1u0XgVtsirsF0M26XQ9YZ8Xn2/e8kph9/X5br7+udbs6MN96D0MeC7gVeNG6PQJ4I97X4+cfvfIorzuQb4zZaIw5BkwGhnkcUyjDgInW7YnAZUHlr5uAeUBDEWkBXALMNMYUGWP2ADOBwXYGZIz5HChyIk7rsfrGmK9M4L/w9aB9ORF3OMOAycaYo8aYTUA+gc9MyM+N9U29PzDFen7we5Bo3NuMMf+zbh8AVgMt8fF7XknM4fji/bbes4PW3erWj6nkWMF/gynAACu2mF5PonE7TZNHeS2BLUH3C6n8w+0GA3wkIotEZKRV1twYsw0C/5BAM6s8XPxevS674mxp3T653Em3WdU748uqfiLEF6q8CbDXGFN8UrmtrGqRcwh8I06K9/ykmMHn77eIpInIEmAngQS7oZJjnYjPenyfFZvf/j8TosmjvFB1ul53R+ttjOkGDAFGiciFlWwbLn6/va5Y43Q7/heAtkBXYBvwhFXuu7hFpC7wH2C0MWZ/ZZuGicX12EPE7Pv32xhTYozpCrQicKXQqZJj+SZuJ2nyKK8QaB10vxWw1aNYADDGbLV+7wTeJvDB3WFVK2D93mltHi5+r16XXXEWWrdPLneEMWaHdbIoBV4m8J7HE/duAtVD6U7ELSLVCZyE/2WM+a9V7Ov3PFTMyfJ+W7HuBT4j0OYR7lgn4rMeb0CgatRv/58J0eRR3kIgx+pFkUGgsWuqV8GISB0RqVd2GxgErLBiKusVcx3wrnV7KnCt1bPmfGCfVXXxITBIRBpZVQKDrDKn2RKn9dgBETnfqju+Nmhftis7+VqGE3jPy+IeYfWmyQZyCDQqh/zcWG0FnwJXWM8Pfg8SjVGAV4HVxpgngx7y7XseLma/v98ikikiDa3btYCBBNprwh0r+G9wBTDLii2m15No3I7zusXebz8EeqWsI1CnOdbjWNoQ6HmxFFhZFg+B+tNPgPXW78ZWuQDPWbEvB3KD9nU9gQa6fOCXDsQ6iUCVw3EC36RusDNOIJfASWUD8CzWAFeH4v6HFdcyAv/ELYK2H2vFsJag3kfhPjfW33CB9XreAmrYFPcFBKo2lgFLrJ9L/fyeVxKzr99v4CxgsRXfCuDeyo4F1LTu51uPt4n39fj5R0eYK6WUiplWWymllIqZJg+llFIx0+ShlFIqZpo8lFJKxUyTh1JKqZhp8lBKKRUzTR5KKaVipslDKaVUzP4fcuDwXPtIpYkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(audio.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768.0\n"
     ]
    }
   ],
   "source": [
    "print(hparams.max_wav_value)\n",
    "# -1から1に標準化\n",
    "audio_norm = audio / hparams.max_wav_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1204dd6a0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(audio_norm.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_norm = audio_norm.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 33181])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_norm.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec = stft.mel_spectrogram(audio_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 130])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melspec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 130])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melspec = torch.squeeze(melspec, 0)\n",
    "melspec.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 入力となるメルスペクトログラムの次元は [mel, frame]\n",
    "- frame長は入力となる波形のサイズによって異なる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.load_mel_from_disk = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TextMelLoader(hparams.training_files, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, mel = trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([107])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 749])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collate_fn: ミニバッチごとに入力データが同じサイズになるようにpaddingする処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = TextMelCollate(hparams.n_frames_per_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, shuffle=False, batch_size=4, pin_memory=False, drop_last=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_padded, input_lengths, mel_padded, gate_padded, output_lengths = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 107])\n",
      "tensor([ 107,   95,   67,   60])\n",
      "torch.Size([4, 80, 750])\n",
      "torch.Size([4, 750])\n",
      "tensor([ 749,  515,  376,  319])\n"
     ]
    }
   ],
   "source": [
    "print(text_padded.size())\n",
    "print(input_lengths)\n",
    "print(mel_padded.size())\n",
    "print(gate_padded.size())\n",
    "print(output_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate_fnの調査用のミニバッチ\n",
    "d1 = trainset[0]\n",
    "d2 = trainset[1]\n",
    "d3 = trainset[4]\n",
    "d4 = trainset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [d1, d2, d3, d4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[107, 60, 121, 107]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各テキストの長さ\n",
    "[len(x[0]) for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 107,   60,  121,  107])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([107, 60, 121, 107])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_lenghtsは降順ソートしたテキストの長さのリスト\n",
    "# 元のインデックス\n",
    "input_lengths, ids_sorted_decreasing = torch.sort(torch.LongTensor([107, 60, 121, 107]), dim=0, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 121,  107,  107,   60])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  0,  3,  1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_sorted_decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_len = input_lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(121)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_padded = torch.LongTensor(len(batch), max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 121])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ids_sorted_decreasing)):\n",
    "    text = batch[ids_sorted_decreasing[i]][0]\n",
    "    text_padded[i, :text.size(0)] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.7000e+01,  4.2000e+01,  6.4000e+01,  4.7000e+01,  3.5000e+01,\n",
       "          3.2000e+01,  6.4000e+01,  4.6000e+01,  4.2000e+01,  4.9000e+01,\n",
       "          3.6000e+01,  3.2000e+01,  4.7000e+01,  6.4000e+01,  3.2000e+01,\n",
       "          4.0000e+01,  2.9000e+01,  2.8000e+01,  4.6000e+01,  4.6000e+01,\n",
       "          5.2000e+01,  6.4000e+01,  3.6000e+01,  4.1000e+01,  6.4000e+01,\n",
       "          5.0000e+01,  2.8000e+01,  4.6000e+01,  3.5000e+01,  3.6000e+01,\n",
       "          4.1000e+01,  3.4000e+01,  4.7000e+01,  4.2000e+01,  4.1000e+01,\n",
       "          5.8000e+01,  6.4000e+01,  3.5000e+01,  3.2000e+01,  6.4000e+01,\n",
       "          2.8000e+01,  4.6000e+01,  3.8000e+01,  3.2000e+01,  3.1000e+01,\n",
       "          6.4000e+01,  2.8000e+01,  2.9000e+01,  4.2000e+01,  4.8000e+01,\n",
       "          4.7000e+01,  6.4000e+01,  4.7000e+01,  3.5000e+01,  3.2000e+01,\n",
       "          6.4000e+01,  3.2000e+01,  4.1000e+01,  4.7000e+01,  4.5000e+01,\n",
       "          2.8000e+01,  4.1000e+01,  3.0000e+01,  3.2000e+01,  6.4000e+01,\n",
       "          4.9000e+01,  3.6000e+01,  4.6000e+01,  2.8000e+01,  4.6000e+01,\n",
       "          6.4000e+01,  3.3000e+01,  4.2000e+01,  4.5000e+01,  6.4000e+01,\n",
       "          5.0000e+01,  3.5000e+01,  3.6000e+01,  3.0000e+01,  3.5000e+01,\n",
       "          6.4000e+01,  3.5000e+01,  3.2000e+01,  6.4000e+01,  2.8000e+01,\n",
       "          4.1000e+01,  3.1000e+01,  6.4000e+01,  3.5000e+01,  3.6000e+01,\n",
       "          4.6000e+01,  6.4000e+01,  5.0000e+01,  3.6000e+01,  3.3000e+01,\n",
       "          3.2000e+01,  6.4000e+01,  3.5000e+01,  2.8000e+01,  3.1000e+01,\n",
       "          6.4000e+01,  4.3000e+01,  4.5000e+01,  3.2000e+01,  4.9000e+01,\n",
       "          3.6000e+01,  4.2000e+01,  4.8000e+01,  4.6000e+01,  3.9000e+01,\n",
       "          5.2000e+01,  6.4000e+01,  2.8000e+01,  4.3000e+01,  4.3000e+01,\n",
       "          3.9000e+01,  3.6000e+01,  3.2000e+01,  3.1000e+01,  6.0000e+01,\n",
       "          1.0000e+00],\n",
       "        [ 4.5000e+01,  6.0000e+01,  6.4000e+01,  4.6000e+01,  6.0000e+01,\n",
       "          6.4000e+01,  4.6000e+01,  4.7000e+01,  4.2000e+01,  4.9000e+01,\n",
       "          2.8000e+01,  3.9000e+01,  3.9000e+01,  5.8000e+01,  6.4000e+01,\n",
       "          2.8000e+01,  4.1000e+01,  3.1000e+01,  6.4000e+01,  3.4000e+01,\n",
       "          6.0000e+01,  6.4000e+01,  3.3000e+01,  6.0000e+01,  6.4000e+01,\n",
       "          4.5000e+01,  4.2000e+01,  4.6000e+01,  3.2000e+01,  6.4000e+01,\n",
       "          4.2000e+01,  2.9000e+01,  4.7000e+01,  2.8000e+01,  3.6000e+01,\n",
       "          4.1000e+01,  3.2000e+01,  3.1000e+01,  6.4000e+01,  2.8000e+01,\n",
       "          6.4000e+01,  4.6000e+01,  3.2000e+01,  2.8000e+01,  4.5000e+01,\n",
       "          3.0000e+01,  3.5000e+01,  6.4000e+01,  5.0000e+01,  2.8000e+01,\n",
       "          4.5000e+01,  4.5000e+01,  2.8000e+01,  4.1000e+01,  4.7000e+01,\n",
       "          6.4000e+01,  2.8000e+01,  4.1000e+01,  3.1000e+01,  6.4000e+01,\n",
       "          3.2000e+01,  5.1000e+01,  2.8000e+01,  4.0000e+01,  3.6000e+01,\n",
       "          4.1000e+01,  3.2000e+01,  3.1000e+01,  6.4000e+01,  4.2000e+01,\n",
       "          4.6000e+01,  5.0000e+01,  2.8000e+01,  3.9000e+01,  3.1000e+01,\n",
       "          5.5000e+01,  4.6000e+01,  6.4000e+01,  3.2000e+01,  3.3000e+01,\n",
       "          3.3000e+01,  3.2000e+01,  3.0000e+01,  4.7000e+01,  4.6000e+01,\n",
       "          6.4000e+01,  3.6000e+01,  4.1000e+01,  6.4000e+01,  4.7000e+01,\n",
       "          3.5000e+01,  3.2000e+01,  6.4000e+01,  4.3000e+01,  2.8000e+01,\n",
       "          3.6000e+01,  4.1000e+01,  3.2000e+01,  6.4000e+01,  3.4000e+01,\n",
       "          2.8000e+01,  4.5000e+01,  2.8000e+01,  3.4000e+01,  3.2000e+01,\n",
       "          6.0000e+01,  1.0000e+00,  6.9987e+18,  8.3884e+18,  8.0979e+18,\n",
       "          7.0708e+18,  8.3912e+18,  7.3055e+18,  8.3152e+18,  6.9266e+18,\n",
       "          7.3106e+18,  2.3149e+18,  7.3069e+18,  8.0263e+18,  7.4530e+18,\n",
       "          7.8873e+18],\n",
       "        [ 4.0000e+01,  3.6000e+01,  4.6000e+01,  4.7000e+01,  3.2000e+01,\n",
       "          4.5000e+01,  6.4000e+01,  2.9000e+01,  4.8000e+01,  5.1000e+01,\n",
       "          4.7000e+01,  4.2000e+01,  4.1000e+01,  5.5000e+01,  4.6000e+01,\n",
       "          6.4000e+01,  4.6000e+01,  4.0000e+01,  2.8000e+01,  3.9000e+01,\n",
       "          3.9000e+01,  6.4000e+01,  5.0000e+01,  4.2000e+01,  4.5000e+01,\n",
       "          3.8000e+01,  6.4000e+01,  4.2000e+01,  4.1000e+01,  6.4000e+01,\n",
       "          4.3000e+01,  4.5000e+01,  3.6000e+01,  4.6000e+01,  4.2000e+01,\n",
       "          4.1000e+01,  6.4000e+01,  3.1000e+01,  3.6000e+01,  4.6000e+01,\n",
       "          3.0000e+01,  3.6000e+01,  4.3000e+01,  3.9000e+01,  3.6000e+01,\n",
       "          4.1000e+01,  3.2000e+01,  6.4000e+01,  3.4000e+01,  2.8000e+01,\n",
       "          4.9000e+01,  3.2000e+01,  6.4000e+01,  2.8000e+01,  6.4000e+01,\n",
       "          4.1000e+01,  3.2000e+01,  5.0000e+01,  6.4000e+01,  2.8000e+01,\n",
       "          4.6000e+01,  4.3000e+01,  3.2000e+01,  3.0000e+01,  4.7000e+01,\n",
       "          6.4000e+01,  4.7000e+01,  4.2000e+01,  6.4000e+01,  4.7000e+01,\n",
       "          3.5000e+01,  3.2000e+01,  6.4000e+01,  4.4000e+01,  4.8000e+01,\n",
       "          3.2000e+01,  4.6000e+01,  4.7000e+01,  3.6000e+01,  4.2000e+01,\n",
       "          4.1000e+01,  6.4000e+01,  3.5000e+01,  3.2000e+01,  6.4000e+01,\n",
       "          3.5000e+01,  2.8000e+01,  3.1000e+01,  6.4000e+01,  4.6000e+01,\n",
       "          4.2000e+01,  6.4000e+01,  4.0000e+01,  4.8000e+01,  3.0000e+01,\n",
       "          3.5000e+01,  6.4000e+01,  2.8000e+01,  4.7000e+01,  6.4000e+01,\n",
       "          3.5000e+01,  3.2000e+01,  2.8000e+01,  4.5000e+01,  4.7000e+01,\n",
       "          6.0000e+01,  1.0000e+00,  2.3369e+18,  8.0306e+18,  6.9987e+18,\n",
       "          8.0978e+18,  8.3861e+18,  7.4494e+18,  7.5954e+18,  8.3900e+18,\n",
       "          7.8099e+18,  2.3149e+18,  8.3898e+18,  2.3400e+18,  6.9987e+18,\n",
       "          7.1622e+18],\n",
       "        [ 4.7000e+01,  3.5000e+01,  3.2000e+01,  6.4000e+01,  3.8000e+01,\n",
       "          4.1000e+01,  4.2000e+01,  5.0000e+01,  3.9000e+01,  3.2000e+01,\n",
       "          3.1000e+01,  3.4000e+01,  3.2000e+01,  6.4000e+01,  2.8000e+01,\n",
       "          4.1000e+01,  3.1000e+01,  6.4000e+01,  4.3000e+01,  4.5000e+01,\n",
       "          2.8000e+01,  3.0000e+01,  4.7000e+01,  3.6000e+01,  3.0000e+01,\n",
       "          3.2000e+01,  6.4000e+01,  4.2000e+01,  3.3000e+01,  6.4000e+01,\n",
       "          3.2000e+01,  4.9000e+01,  3.2000e+01,  4.5000e+01,  5.2000e+01,\n",
       "          6.4000e+01,  4.6000e+01,  4.3000e+01,  3.2000e+01,  3.0000e+01,\n",
       "          3.6000e+01,  3.2000e+01,  4.6000e+01,  6.4000e+01,  4.2000e+01,\n",
       "          3.3000e+01,  6.4000e+01,  3.0000e+01,  4.5000e+01,  3.6000e+01,\n",
       "          4.0000e+01,  3.6000e+01,  4.1000e+01,  2.8000e+01,  3.9000e+01,\n",
       "          3.6000e+01,  4.7000e+01,  5.2000e+01,  6.0000e+01,  1.0000e+00,\n",
       "          2.3149e+18,  8.3152e+18,  3.2553e+18,  2.3149e+18,  8.0306e+18,\n",
       "          2.3149e+18,  7.3072e+18,  7.9559e+18,  7.5752e+18,  2.3183e+18,\n",
       "          7.9391e+18,  6.9987e+18,  7.2368e+18,  7.3590e+18,  2.3087e+18,\n",
       "          8.1012e+18,  2.3149e+18,  3.2553e+18,  4.4851e+18,  7.5966e+18,\n",
       "          6.8780e+18,  3.1841e+18,  2.9688e+18,  2.3087e+18,  7.9354e+18,\n",
       "          7.3123e+18,  7.9560e+18,  7.9354e+18,  2.3087e+18,  2.3149e+18,\n",
       "          8.2459e+18,  7.0164e+18,  7.3061e+18,  7.2368e+18,  2.3149e+18,\n",
       "          2.3149e+18,  8.2459e+18,  7.0164e+18,  7.3061e+18,  7.5943e+18,\n",
       "          2.3149e+18,  7.0173e+18,  8.3912e+18,  2.3386e+18,  8.3140e+18,\n",
       "          2.3149e+18,  2.3149e+18,  8.0306e+18,  2.3383e+18,  8.3917e+18,\n",
       "          7.9594e+18,  6.9987e+18,  2.3347e+18,  8.0281e+18,  2.3149e+18,\n",
       "          7.8865e+18,  8.6743e+18,  8.6755e+18,  7.5943e+18,  7.4544e+18,\n",
       "          4.4294e+18]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 749])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_mels = batch[0][1].size(0)\n",
    "num_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[749, 319, 635, 543]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ミニバッチ内のメルスペクトログラムの系列長\n",
    "[x[1].size(1) for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_target_len = max([749, 319, 635, 543]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.n_frames_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_target_len % hparams.n_frames_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80, 750])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_padded = torch.FloatTensor(len(batch), num_mels, max_target_len)\n",
    "mel_padded.zero_()\n",
    "mel_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 750])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# これは何に使う？ 系列長の長さのバッチみたい\n",
    "# 0でpaddingしたところを1にしている？\n",
    "gate_padded = torch.FloatTensor(len(batch), max_target_len)\n",
    "gate_padded.zero_()\n",
    "gate_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# オリジナルの系列長\n",
    "output_lengths = torch.LongTensor(len(batch))\n",
    "output_lengths.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  0,  3,  1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テキストのソート順\n",
    "ids_sorted_decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ids_sorted_decreasing)):\n",
    "    mel = batch[ids_sorted_decreasing[i]][1]\n",
    "    mel_padded[i, :, :mel.size(1)] = mel\n",
    "    gate_padded[i, mel.size(1):] = 1  # paddingしたところを1にしている？\n",
    "    output_lengths[i] = mel.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80, 750])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 635,  749,  543,  319])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=4, pin_memory=False, drop_last=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 116]) tensor([ 116,  115,  106,   63]) torch.Size([4, 80, 676]) torch.Size([4, 676]) torch.Size([4]) tensor([ 611,  675,  574,  346])\n"
     ]
    }
   ],
   "source": [
    "text_padded, input_lengths, mel_padded, gate_padded, output_lengths = iter(train_loader).next()\n",
    "print(text_padded.size(), input_lengths, mel_padded.size(), gate_padded.size(), output_lengths.size(), output_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 158]) tensor([ 158,  138,   72,   19]) torch.Size([4, 80, 832])\n"
     ]
    }
   ],
   "source": [
    "text_padded, input_lengths, mel_padded, gate_padded, output_lengths = iter(train_loader).next()\n",
    "print(text_padded.size(), input_lengths, mel_padded.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([4, 108]) torch.Size([4]) torch.Size([4, 80, 547]) torch.Size([4, 547]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    print(i, batch[0].size(), batch[1].size(), batch[2].size(), batch[3].size(), batch[4].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batchは (text_padded, input_lengths, mel_padded, gate_padded, output_lenghts) の5つ組\n",
    "- text_padded: zero paddingされたテキスト系列 (batch, text_length)\n",
    "- input_lengths: テキストのオリジナルの系列長 (batch, )\n",
    "- mel_padded: メルスペクトログラムのzero paddingされた系列長 (batch, num_mels, frame)\n",
    "- gate_padded: メルスペクトログラムでzero paddingされたところが1 (batch, frame)\n",
    "- output_lengths: メルスペクトログラムのオリジナルの系列長 (batch, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 163]) torch.Size([4]) torch.Size([4, 80, 780]) torch.Size([4, 780]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "batch = iter(train_loader).next()\n",
    "print(batch[0].size(), batch[1].size(), batch[2].size(), batch[3].size(), batch[4].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:35: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n",
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "from model import Tacotron2, Encoder\n",
    "model = Tacotron2(hparams).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_parser = model.parse_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = batch_parser(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 163])\n",
      "torch.Size([4]) tensor([ 163,  121,  100,   76])\n",
      "torch.Size([4, 80, 780])\n",
      "163\n",
      "torch.Size([4]) tensor([ 779,  697,  627,  514])\n"
     ]
    }
   ],
   "source": [
    "print(x[0].size())\n",
    "print(x[1].size(), x[1])\n",
    "print(x[2].size())\n",
    "print(x[3])  # maxlen\n",
    "print(x[4].size(), x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 80, 780])\n",
      "torch.Size([4, 780])\n"
     ]
    }
   ],
   "source": [
    "print(y[0].size())\n",
    "print(y[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x: text_padded, input_lengths, mel_padded, max(input_lenghts), output_lengths\n",
    "- y: mel_padded, gate_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:35: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n",
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "from model import Tacotron2, Encoder\n",
    "model = Tacotron2(hparams).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** x: torch.Size([4, 512, 163])\n",
      "*** input_lengths: tensor([ 163,  121,  100,   76])\n",
      "*** conv: torch.Size([4, 512, 163])\n",
      "*** conv: torch.Size([4, 512, 163])\n",
      "*** conv: torch.Size([4, 512, 163])\n",
      "*** transpose: torch.Size([4, 163, 512])\n",
      "*** torch.Size([460, 512])\n",
      "*** outputs: torch.Size([460, 512])\n",
      "*** output: torch.Size([4, 163, 512])\n",
      "*** memory: torch.Size([4, 163, 512])\n",
      "*** decoder_input: torch.Size([4, 80])\n",
      "attention_hidden: torch.Size([4, 1024])\n",
      "attention_cell: torch.Size([4, 1024])\n",
      "decoder_hidden: torch.Size([4, 1024])\n",
      "decoder_cell: torch.Size([4, 1024])\n",
      "attention_weights: torch.Size([4, 163])\n",
      "attention_weights_cum: torch.Size([4, 163])\n",
      "attention_context: torch.Size([4, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[-4.2111e-03, -7.8068e-02, -2.2712e-01,  ..., -1.5912e-01,\n",
       "           -4.3394e-01, -3.6552e-01],\n",
       "          [-5.8458e-02, -9.1870e-02,  8.7890e-02,  ..., -1.5803e-01,\n",
       "           -2.1279e-01, -2.7359e-01],\n",
       "          [ 5.6512e-02,  3.1115e-01,  9.8136e-03,  ..., -6.4732e-03,\n",
       "           -4.1777e-02,  4.4706e-02],\n",
       "          ...,\n",
       "          [-1.3845e-01,  7.1028e-02, -2.9720e-01,  ..., -4.4055e-02,\n",
       "           -1.1924e-01,  2.1763e-01],\n",
       "          [-7.3988e-02, -2.6394e-01, -2.1377e-01,  ...,  1.1835e-01,\n",
       "            1.0732e-01, -5.9689e-02],\n",
       "          [-2.0237e-03,  7.8121e-02, -2.2514e-01,  ..., -3.9958e-01,\n",
       "           -3.1027e-01, -4.8566e-01]],\n",
       " \n",
       "         [[-1.4365e-02, -1.7603e-01, -4.1345e-01,  ..., -4.3732e-02,\n",
       "           -4.3734e-02, -4.3737e-02],\n",
       "          [-4.1823e-02, -6.0722e-02, -6.5373e-02,  ..., -6.1569e-02,\n",
       "           -6.1569e-02, -6.1569e-02],\n",
       "          [ 7.3492e-02,  1.6417e-01,  1.7069e-01,  ...,  7.7085e-02,\n",
       "            7.7085e-02,  7.7085e-02],\n",
       "          ...,\n",
       "          [-1.4195e-01,  3.9275e-01,  6.0987e-02,  ..., -1.6264e-01,\n",
       "           -1.6266e-01, -1.6267e-01],\n",
       "          [-4.9635e-02,  8.4888e-02,  1.3098e-01,  ..., -5.4870e-02,\n",
       "           -5.4879e-02, -5.4887e-02],\n",
       "          [-4.1438e-02,  3.2737e-01,  1.0843e-01,  ..., -1.3842e-02,\n",
       "           -1.3847e-02, -1.3851e-02]],\n",
       " \n",
       "         [[ 2.2537e-02,  1.5792e-01, -1.1348e-01,  ...,  5.7010e-03,\n",
       "            5.7115e-03,  5.7221e-03],\n",
       "          [-5.5048e-02, -3.0543e-01, -5.5758e-01,  ..., -7.8482e-02,\n",
       "           -7.8492e-02, -7.8503e-02],\n",
       "          [ 5.8672e-02,  2.1621e-01, -7.6384e-02,  ...,  7.4471e-02,\n",
       "            7.4469e-02,  7.4467e-02],\n",
       "          ...,\n",
       "          [-1.4348e-01,  1.2106e-01, -1.9561e-04,  ..., -1.5648e-01,\n",
       "           -1.5645e-01, -1.5643e-01],\n",
       "          [-8.0980e-02,  1.3230e-01,  1.3915e-01,  ..., -8.2383e-02,\n",
       "           -8.2397e-02, -8.2410e-02],\n",
       "          [-1.9302e-02, -3.7313e-01, -2.0917e-02,  ..., -1.3113e-02,\n",
       "           -1.3124e-02, -1.3135e-02]],\n",
       " \n",
       "         [[ 4.9656e-03, -2.9702e-01, -2.5269e-01,  ..., -3.1609e-02,\n",
       "           -3.1608e-02, -3.1607e-02],\n",
       "          [-5.6643e-02,  1.3227e-01, -2.5818e-01,  ..., -7.6921e-02,\n",
       "           -7.6918e-02, -7.6915e-02],\n",
       "          [ 7.5287e-02, -1.3786e-01,  3.8970e-02,  ...,  7.8117e-02,\n",
       "            7.8112e-02,  7.8107e-02],\n",
       "          ...,\n",
       "          [-1.5263e-01, -1.0854e-01,  3.1180e-02,  ..., -1.6870e-01,\n",
       "           -1.6869e-01, -1.6869e-01],\n",
       "          [-4.3505e-02, -3.4091e-01,  5.0753e-02,  ..., -2.7414e-02,\n",
       "           -2.7436e-02, -2.7458e-02],\n",
       "          [-2.0193e-02, -7.0052e-02, -1.4587e-01,  ..., -8.4727e-03,\n",
       "           -8.4778e-03, -8.4829e-03]]]),\n",
       " tensor([[[-4.2111e-03, -7.8068e-02, -2.4843e-01,  ..., -9.6871e-01,\n",
       "           -1.3606e+00, -9.4497e-01],\n",
       "          [-4.6763e-02, -9.1870e-02,  8.7890e-02,  ...,  4.1919e-01,\n",
       "           -2.1279e-01, -2.7359e-01],\n",
       "          [ 5.6512e-02,  3.1115e-01,  9.8136e-03,  ...,  2.3979e+00,\n",
       "            1.2220e+00, -3.8188e-01],\n",
       "          ...,\n",
       "          [-1.3845e-01,  7.1028e-02, -2.9720e-01,  ..., -5.4292e-01,\n",
       "           -9.0689e-01,  2.1763e-01],\n",
       "          [-7.2902e-02, -2.6394e-01, -2.1377e-01,  ...,  7.3416e-03,\n",
       "           -8.1305e-02, -2.7069e-01],\n",
       "          [-2.0237e-03,  7.8121e-02, -2.2514e-01,  ..., -7.1941e-01,\n",
       "           -4.7430e-01, -4.8566e-01]],\n",
       " \n",
       "         [[ 2.9659e-04, -8.7436e-02, -4.1345e-01,  ..., -4.3732e-02,\n",
       "           -6.1275e-01,  4.2122e-01],\n",
       "          [-4.1823e-02, -6.0722e-02, -6.5373e-02,  ..., -6.1569e-02,\n",
       "           -1.8401e-01, -4.5370e-01],\n",
       "          [ 7.3492e-02,  1.6417e-01,  1.1862e+00,  ...,  2.2858e-01,\n",
       "            7.7085e-02, -1.0834e+00],\n",
       "          ...,\n",
       "          [-1.6311e-01, -8.3362e-03,  2.3760e-01,  ..., -6.6536e-01,\n",
       "            3.9795e-02, -1.6267e-01],\n",
       "          [-2.8551e-01,  3.0898e-01,  1.2219e-01,  ..., -5.4870e-02,\n",
       "           -1.4488e-01, -1.7983e-01],\n",
       "          [-4.1438e-02, -7.2376e-01, -1.3326e-01,  ...,  1.4856e-01,\n",
       "           -1.3847e-02, -1.3851e-02]],\n",
       " \n",
       "         [[ 2.2537e-02,  1.5792e-01, -1.1348e-01,  ..., -2.1008e-01,\n",
       "            1.0520e+00,  5.7221e-03],\n",
       "          [-3.2434e-01, -4.0951e-01, -4.8534e-01,  ..., -7.8482e-02,\n",
       "            8.8262e-02, -7.8503e-02],\n",
       "          [ 5.8672e-02,  2.1621e-01, -7.6384e-02,  ...,  7.4471e-02,\n",
       "            7.4469e-02,  6.7931e-01],\n",
       "          ...,\n",
       "          [-1.4348e-01,  1.2106e-01, -1.9561e-04,  ..., -5.2985e-01,\n",
       "           -1.5645e-01, -1.5643e-01],\n",
       "          [ 1.6722e-01,  1.2500e-01,  1.3915e-01,  ..., -8.2383e-02,\n",
       "           -8.2397e-02, -8.2410e-02],\n",
       "          [-1.9302e-02, -1.1457e+00, -2.0917e-02,  ..., -1.3113e-02,\n",
       "           -1.3124e-02, -1.0404e+00]],\n",
       " \n",
       "         [[ 4.0272e-01, -3.8128e-01,  5.0642e-01,  ..., -3.5974e-01,\n",
       "           -3.1608e-02, -2.8492e-01],\n",
       "          [-5.6643e-02,  4.7673e-01,  2.9776e-01,  ..., -7.6921e-02,\n",
       "           -7.6918e-02, -7.6915e-02],\n",
       "          [-3.2398e-03,  1.6770e+00,  3.8970e-02,  ...,  7.8117e-02,\n",
       "            7.8112e-02,  7.8107e-02],\n",
       "          ...,\n",
       "          [-1.5263e-01, -1.0854e-01,  3.1180e-02,  ..., -4.5758e-01,\n",
       "           -1.6869e-01, -1.6869e-01],\n",
       "          [-4.3505e-02, -3.4091e-01,  1.2448e-01,  ...,  3.9685e-01,\n",
       "           -2.7436e-02, -2.7458e-02],\n",
       "          [ 2.3628e-01, -7.0052e-02, -1.4587e-01,  ..., -8.2397e-01,\n",
       "            5.3084e-01, -8.4829e-03]]]),\n",
       " tensor([[-0.0231,  0.1348,  0.2627,  ..., -0.0560, -0.3972, -0.0496],\n",
       "         [-0.0167, -0.2220, -0.3065,  ..., -0.0345, -0.0345, -0.0345],\n",
       "         [-0.0202, -0.2841, -0.1370,  ..., -0.0389, -0.0389, -0.0390],\n",
       "         [-0.0253, -0.2373, -0.1793,  ..., -0.0194, -0.0194, -0.0194]]),\n",
       " tensor(1.00000e-02 *\n",
       "        [[[ 0.7483,  0.7578,  0.5709,  ...,  0.5665,  0.5702,  0.6148],\n",
       "          [ 0.7528,  0.7616,  0.5762,  ...,  0.5659,  0.5692,  0.6148],\n",
       "          [ 0.7508,  0.7596,  0.5776,  ...,  0.5691,  0.5682,  0.6116],\n",
       "          ...,\n",
       "          [ 2.0409,  1.8472,  0.6081,  ...,  0.8616,  0.4760,  0.4632],\n",
       "          [ 2.0068,  1.8498,  0.6009,  ...,  0.8183,  0.4734,  0.4599],\n",
       "          [ 2.0378,  1.7993,  0.6031,  ...,  0.8635,  0.4916,  0.4833]],\n",
       " \n",
       "         [[ 0.4522,  0.4731,  0.2661,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.4561,  0.4753,  0.2680,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.4597,  0.4714,  0.2685,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 1.8768,  1.8296,  0.6043,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.8766,  1.8296,  0.6045,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.8765,  1.8296,  0.6046,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 1.0926,  0.8100,  0.6740,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.0978,  0.8158,  0.6750,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.0886,  0.8160,  0.6683,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 2.7120,  1.5957,  0.7818,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 2.7103,  1.5956,  0.7815,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 2.7086,  1.5955,  0.7812,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 1.6341,  1.4704,  1.1116,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.6474,  1.4801,  1.1192,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.6575,  1.4852,  1.1256,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 2.9641,  2.1087,  1.2158,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 2.9627,  2.1066,  1.2163,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 2.9613,  2.1044,  1.2168,  ...,  0.0000,  0.0000,  0.0000]]])]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, input_lengths, targets, max_len, output_lengths = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths, output_lengths = input_lengths.data, output_lengths.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 163,  121,  100,   76])\n",
      "tensor([ 779,  697,  627,  514])\n"
     ]
    }
   ],
   "source": [
    "print(input_lengths)   # テキストの系列長　\n",
    "print(output_lengths)  # メルスペクトログラムの系列長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_inputs = model.embedding(inputs).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 163])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_inputs.size()  # [batch, feature, seq] PyTorchのConv1dの入力サイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:35: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n",
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "from model import Tacotron2, Encoder\n",
    "model = Tacotron2(hparams).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 163])\n",
      "tensor([ 163,  121,  100,   76])\n"
     ]
    }
   ],
   "source": [
    "print(embedded_inputs.size())\n",
    "print(input_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** x: torch.Size([4, 512, 163])\n",
      "*** input_lengths: tensor([ 163,  121,  100,   76])\n",
      "*** conv: torch.Size([4, 512, 163])\n",
      "*** conv: torch.Size([4, 512, 163])\n",
      "*** conv: torch.Size([4, 512, 163])\n",
      "*** transpose: torch.Size([4, 163, 512])\n",
      "*** torch.Size([460, 512])\n",
      "*** outputs: torch.Size([460, 512])\n",
      "*** output: torch.Size([4, 163, 512])\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs = model.encoder(embedded_inputs, input_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 163, 512])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 256, batch_first=True, bidirectional=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(512, 256, 1, batch_first=True, bidirectional=True)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flatten_parameters()はマルチGPUで必要な処理？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 256, batch_first=True, bidirectional=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.flatten_parameters()\n",
    "lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 163, 512])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoderのattention weightsを計算するのに使われる\n",
    "encoder_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80, 780])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 163,  121,  100,   76])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_lengths = input_lengths\n",
    "memory_lengths  # バッチを構成する入力テキストの系列長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "1\n",
      "512\n",
      "1024\n",
      "1024\n",
      "256\n",
      "1000\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "print(hparams.n_mel_channels)\n",
    "print(hparams.n_frames_per_step)\n",
    "print(hparams.encoder_embedding_dim)\n",
    "print(hparams.attention_rnn_dim)\n",
    "print(hparams.decoder_rnn_dim)\n",
    "print(hparams.prenet_dim)\n",
    "print(hparams.max_decoder_steps)\n",
    "print(hparams.gate_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = encoder_outputs  # エンコーダの出力（テキスト特徴量）\n",
    "decoder_inputs = targets  # メルスペクトログラム（出力となる）\n",
    "memory_lengths = input_lengths  # バッチを構成する入力テキストの系列長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 163, 512])\n",
      "torch.Size([4, 80, 780])\n",
      "tensor([ 163,  121,  100,   76])\n"
     ]
    }
   ],
   "source": [
    "print(memory.size())\n",
    "print(decoder_inputs.size())\n",
    "print(memory_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n",
      "/Users/koichiro.mori/git/tacotron2/layers.py:35: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = decoder.get_go_frame(memory)\n",
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = decoder.parse_decoder_inputs(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([780, 4, 80])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs.size()  # (seqlen, batch, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -7.9470,  -7.1068,  -6.4366,  ...,  -8.7415,  -8.6529,\n",
       "           -9.1134],\n",
       "         [ -8.1235,  -6.3942,  -5.8867,  ...,  -9.5579,  -9.6605,\n",
       "           -9.8809],\n",
       "         [ -6.8018,  -5.8457,  -6.0552,  ...,  -8.8050,  -9.2375,\n",
       "          -10.5610],\n",
       "         [ -6.1744,  -6.3822,  -6.3996,  ...,  -9.9191, -10.0493,\n",
       "          -10.8555]],\n",
       "\n",
       "        [[ -7.6436,  -7.0450,  -6.1906,  ...,  -8.3608,  -8.2883,\n",
       "           -9.1178],\n",
       "         [ -8.2578,  -6.6928,  -5.9495,  ...,  -9.4310,  -9.6945,\n",
       "           -9.8029],\n",
       "         [ -6.3901,  -5.9171,  -5.2944,  ...,  -5.7075,  -6.1652,\n",
       "           -8.0939],\n",
       "         [ -6.6239,  -6.7819,  -5.7135,  ...,  -9.4868,  -9.9183,\n",
       "          -10.5577]],\n",
       "\n",
       "        [[ -7.1368,  -6.2999,  -5.3963,  ...,  -6.9938,  -7.5920,\n",
       "           -9.2136],\n",
       "         [ -8.3706,  -7.0172,  -6.5367,  ...,  -9.5467,  -9.5898,\n",
       "          -10.1134],\n",
       "         [ -7.2332,  -6.1908,  -5.3871,  ...,  -4.8795,  -5.3569,\n",
       "           -7.0563],\n",
       "         [ -6.3462,  -5.8769,  -5.1226,  ...,  -9.2160,  -9.3219,\n",
       "           -9.1734]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -6.7687,  -6.0647,  -5.6039,  ...,  -9.6751,  -9.9702,\n",
       "          -10.5580],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "        [[ -6.3737,  -6.7325,  -6.2279,  ...,  -9.7096, -10.0112,\n",
       "          -10.4529],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "        [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
       "            0.0000]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 163, 512])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 163,  121,  100,   76])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~get_mask_from_lengths(memory_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_hidden: torch.Size([4, 1024])\n",
      "attention_cell: torch.Size([4, 1024])\n",
      "decoder_hidden: torch.Size([4, 1024])\n",
      "decoder_cell: torch.Size([4, 1024])\n",
      "attention_weights: torch.Size([4, 163])\n",
      "attention_weights_cum: torch.Size([4, 163])\n",
      "attention_context: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "decoder.initialize_decoder_states(memory, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs, gate_outputs, alignments = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 163, 512])\n",
      "torch.Size([4, 80, 780])\n",
      "tensor([ 163,  121,  100,   76])\n",
      "*** memory: torch.Size([4, 163, 512])\n",
      "*** decoder_input: torch.Size([4, 80])\n",
      "attention_hidden: torch.Size([4, 1024])\n",
      "attention_cell: torch.Size([4, 1024])\n",
      "decoder_hidden: torch.Size([4, 1024])\n",
      "decoder_cell: torch.Size([4, 1024])\n",
      "attention_weights: torch.Size([4, 163])\n",
      "attention_weights_cum: torch.Size([4, 163])\n",
      "attention_context: torch.Size([4, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-4.7202e-02, -6.2895e-01, -2.5581e-01,  ..., -6.3293e-01,\n",
       "           -4.0786e-01, -7.2768e-01],\n",
       "          [ 1.8926e-02,  2.9120e-01,  6.4308e-02,  ..., -6.7519e-02,\n",
       "            4.3046e-02,  2.2482e-01],\n",
       "          [ 5.4296e-02, -7.4026e-02, -3.6574e-02,  ...,  1.8612e-01,\n",
       "           -1.8707e-01, -2.3050e-02],\n",
       "          ...,\n",
       "          [ 1.0338e-01, -2.2023e-01, -8.3709e-03,  ..., -6.3593e-02,\n",
       "            1.8228e-01, -2.5440e-01],\n",
       "          [-2.0900e-02,  5.4765e-02, -1.7301e-02,  ...,  7.2265e-02,\n",
       "            1.7886e-01,  3.1559e-01],\n",
       "          [ 1.5614e-02, -8.7630e-02, -6.7494e-02,  ..., -2.3097e-01,\n",
       "           -1.7160e-01, -3.0105e-01]],\n",
       " \n",
       "         [[-4.7354e-02,  2.2333e-01, -3.3355e-01,  ..., -4.8253e-02,\n",
       "           -4.8250e-02, -4.8247e-02],\n",
       "          [ 1.7266e-02, -4.4502e-02,  5.4839e-01,  ...,  2.5642e-02,\n",
       "            2.5637e-02,  2.5632e-02],\n",
       "          [ 1.6263e-02, -1.4340e-02,  2.4605e-01,  ..., -2.1030e-02,\n",
       "           -2.1035e-02, -2.1039e-02],\n",
       "          ...,\n",
       "          [ 1.0277e-01,  2.0270e-01,  1.9167e-01,  ...,  9.0595e-02,\n",
       "            9.0595e-02,  9.0594e-02],\n",
       "          [-2.9322e-02,  2.8456e-01, -2.5198e-01,  ..., -2.9101e-02,\n",
       "           -2.9111e-02, -2.9120e-02],\n",
       "          [ 5.8486e-03, -3.2650e-02, -2.3054e-01,  ...,  7.9671e-03,\n",
       "            7.9647e-03,  7.9623e-03]],\n",
       " \n",
       "         [[-3.0353e-02,  2.8851e-01,  4.3749e-01,  ..., -4.0427e-02,\n",
       "           -4.0453e-02, -4.0479e-02],\n",
       "          [ 9.0580e-03,  3.5344e-02,  1.8780e-01,  ..., -2.2970e-03,\n",
       "           -2.3128e-03, -2.3285e-03],\n",
       "          [ 3.2785e-02,  4.4741e-01,  1.4160e-01,  ...,  4.2610e-03,\n",
       "            4.2760e-03,  4.2909e-03],\n",
       "          ...,\n",
       "          [ 9.3267e-02, -4.0892e-01,  2.4500e-01,  ...,  8.5088e-02,\n",
       "            8.5095e-02,  8.5103e-02],\n",
       "          [-2.3065e-02,  4.1787e-03, -8.8645e-02,  ..., -1.6774e-02,\n",
       "           -1.6769e-02, -1.6764e-02],\n",
       "          [ 7.2209e-03,  2.6252e-01, -1.1566e-01,  ..., -3.9086e-03,\n",
       "           -3.9270e-03, -3.9453e-03]],\n",
       " \n",
       "         [[-3.9828e-02, -1.0820e-01,  7.7195e-02,  ..., -5.7082e-02,\n",
       "           -5.7105e-02, -5.7128e-02],\n",
       "          [ 3.2617e-02, -2.9193e-01, -2.9059e-01,  ...,  5.2398e-02,\n",
       "            5.2402e-02,  5.2407e-02],\n",
       "          [ 3.7856e-02,  2.5261e-01, -5.9370e-02,  ...,  2.1526e-03,\n",
       "            2.1439e-03,  2.1352e-03],\n",
       "          ...,\n",
       "          [ 1.2847e-01, -1.5305e-02,  5.8600e-02,  ...,  1.1568e-01,\n",
       "            1.1568e-01,  1.1568e-01],\n",
       "          [-1.7453e-02,  2.0633e-02,  1.8155e-01,  ...,  1.2560e-02,\n",
       "            1.2536e-02,  1.2512e-02],\n",
       "          [-3.0773e-02,  8.9346e-02, -4.6978e-02,  ..., -1.5838e-02,\n",
       "           -1.5840e-02, -1.5843e-02]]]),\n",
       " tensor([[ 0.0483, -0.1397, -0.1769,  ..., -0.5739, -0.3355, -0.3474],\n",
       "         [ 0.0634,  0.0666, -0.0455,  ...,  0.0582,  0.0583,  0.0583],\n",
       "         [ 0.0284,  0.1968,  0.0943,  ...,  0.0337,  0.0337,  0.0336],\n",
       "         [ 0.0444, -0.0926, -0.2135,  ...,  0.0466,  0.0466,  0.0466]]),\n",
       " tensor(1.00000e-02 *\n",
       "        [[[ 0.9626,  0.8040,  0.7812,  ...,  1.2295,  0.8233,  0.9132],\n",
       "          [ 0.9630,  0.8066,  0.7860,  ...,  1.2303,  0.8248,  0.9121],\n",
       "          [ 0.9687,  0.8198,  0.7921,  ...,  1.2208,  0.8204,  0.9116],\n",
       "          ...,\n",
       "          [ 1.8141,  2.0871,  0.7840,  ...,  2.9774,  0.4615,  0.3981],\n",
       "          [ 1.8185,  2.1812,  0.7913,  ...,  3.0387,  0.4569,  0.3835],\n",
       "          [ 1.7888,  2.1071,  0.7923,  ...,  3.1930,  0.4533,  0.3959]],\n",
       " \n",
       "         [[ 0.6938,  0.6336,  0.7152,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.6965,  0.6366,  0.7167,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.7049,  0.6437,  0.7198,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 1.8133,  1.5174,  1.9468,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.8130,  1.5177,  1.9485,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.8128,  1.5180,  1.9501,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 1.4043,  1.5888,  0.6459,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.4093,  1.5954,  0.6477,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.4035,  1.5989,  0.6449,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 3.4673,  2.5175,  0.4108,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 3.4645,  2.5162,  0.4106,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 3.4616,  2.5150,  0.4105,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 1.3867,  1.2855,  0.9224,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.3917,  1.2882,  0.9246,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.4041,  1.3038,  0.9365,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 3.0932,  1.4411,  0.4803,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 3.0921,  1.4373,  0.4801,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 3.0910,  1.4336,  0.4798,  ...,  0.0000,  0.0000,  0.0000]]]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = encoder_outputs  # テキスト特徴量\n",
    "decoder_inputs = targets  # メルスペクトログラム（出力となる）\n",
    "memory_lengths = input_lengths  # バッチを構成する入力テキストの系列長\n",
    "print(memory.size())\n",
    "print(decoder_inputs.size())\n",
    "print(memory_lengths)\n",
    "\n",
    "decoder(memory, decoder_inputs, memory_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "1\n",
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prenet(\n",
       "  (layers): ModuleList(\n",
       "    (0): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n",
       "    )\n",
       "    (1): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hparams.n_mel_channels)\n",
    "print(hparams.n_frames_per_step)\n",
    "print(hparams.prenet_dim)\n",
    "prenet = Prenet(80 * 1, [256, 256])\n",
    "prenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "512\n",
      "1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMCell(1536, 1024)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hparams.decoder_rnn_dim)\n",
    "print(hparams.encoder_embedding_dim)\n",
    "print(hparams.attention_rnn_dim)\n",
    "attention_rnn = nn.LSTMCell(1024 + 512, 1024)\n",
    "attention_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "512\n",
      "1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMCell(768, 1024, bias=1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hparams.prenet_dim)\n",
    "print(hparams.encoder_embedding_dim)\n",
    "print(hparams.decoder_rnn_dim)\n",
    "decoder_rnn = nn.LSTMCell(256 + 512, 1024, 1)\n",
    "decoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "512\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearNorm(\n",
       "  (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hparams.decoder_rnn_dim)\n",
    "print(hparams.encoder_embedding_dim)\n",
    "print(hparams.n_mel_channels)\n",
    "linear_projection = LinearNorm(1024 + 512, 80)\n",
    "linear_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "gate_layer = LinearNorm(1024 + 512, 1, bias=True, w_init_gain='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearNorm(\n",
       "  (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 163, 512])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 163)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = memory.size(0)\n",
    "MAX_TIME = memory.size(1)\n",
    "B, MAX_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hparams.attention_rnn_dim)\n",
    "memory.data.new(B, 1024).zero_().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 163, 512])\n",
      "torch.Size([4, 80, 780])\n",
      "tensor([ 163,  121,  100,   76])\n"
     ]
    }
   ],
   "source": [
    "print(memory.size())\n",
    "print(decoder_inputs.size())\n",
    "print(memory_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** memory: torch.Size([4, 163, 512])\n",
      "*** decoder_input: torch.Size([4, 80])\n",
      "attention_hidden: torch.Size([4, 1024])\n",
      "attention_cell: torch.Size([4, 1024])\n",
      "decoder_hidden: torch.Size([4, 1024])\n",
      "decoder_cell: torch.Size([4, 1024])\n",
      "attention_weights: torch.Size([4, 163])\n",
      "attention_weights_cum: torch.Size([4, 163])\n",
      "attention_context: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "mel_outputs, gate_outputs, alignments = decoder(memory, decoder_inputs, memory_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 80, 780])\n",
      "torch.Size([4, 780])\n",
      "torch.Size([4, 780, 163])\n"
     ]
    }
   ],
   "source": [
    "print(mel_outputs.size())\n",
    "print(gate_outputs.size())\n",
    "print(alignments.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.attention_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "512\n",
      "128\n",
      "32\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(hparams.attention_rnn_dim)\n",
    "print(hparams.encoder_embedding_dim)\n",
    "print(hparams.attention_dim)\n",
    "print(hparams.attention_location_n_filters)\n",
    "print(hparams.attention_location_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/git/tacotron2/layers.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  gain=torch.nn.init.calculate_gain(w_init_gain))\n",
      "/Users/koichiro.mori/git/tacotron2/layers.py:35: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n"
     ]
    }
   ],
   "source": [
    "attention_layer = Attention(1024, 512, 128, 32, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.Attention"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (query_layer): LinearNorm(\n",
       "    (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
       "  )\n",
       "  (memory_layer): LinearNorm(\n",
       "    (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n",
       "  )\n",
       "  (v): LinearNorm(\n",
       "    (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n",
       "  )\n",
       "  (location_layer): LocationLayer(\n",
       "    (location_conv): ConvNorm(\n",
       "      (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n",
       "    )\n",
       "    (location_dense): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 163, 512])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 163, 128])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory_layerは単純なLinear変換\n",
    "# embedding_dim (512) を attention_dim (128) に次元圧縮している\n",
    "processed_memory = attention_layer.memory_layer(memory)\n",
    "processed_memory.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoderの最初の入力を0で初期化\n",
    "decoder_input = decoder.get_go_frame(memory)\n",
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024])\n",
      "torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "print(decoder.decoder_hidden.size())\n",
    "print(decoder.attention_context.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1536])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_input = torch.cat((decoder.decoder_hidden, decoder.attention_context), -1)\n",
    "cell_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.attention_hidden, decoder.attention_cell = decoder.attention_rnn(cell_input, (decoder.attention_hidden, decoder.attention_cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [[ 1.3329,  0.0715, -1.1153,  ...,  2.9965, -0.5315, -0.6198],\n",
       "        [ 1.3329,  0.0715, -1.1153,  ...,  2.9965, -0.5315, -0.6198],\n",
       "        [ 1.3329,  0.0715, -1.1153,  ...,  2.9965, -0.5315, -0.6198],\n",
       "        [ 1.3329,  0.0715, -1.1153,  ...,  2.9965, -0.5315, -0.6198]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.attention_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMCell(1536, 1024)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.attention_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
