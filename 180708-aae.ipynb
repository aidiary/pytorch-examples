{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 32\n",
    "z_dim = 5\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "Q = nn.Sequential(\n",
    "    nn.Linear(X_dim, h_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(h_dim, z_dim)\n",
    ")\n",
    "\n",
    "# Decoder\n",
    "P = nn.Sequential(\n",
    "    nn.Linear(z_dim, h_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(h_dim, X_dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Descriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(z_dim, h_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(h_dim, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    Q.zero_grad()\n",
    "    P.zero_grad()\n",
    "    D.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_X(size, include_y=False):\n",
    "    X, y = mnist.train.next_batch(size)\n",
    "    X = torch.from_numpy(X)\n",
    "    \n",
    "    if include_y:\n",
    "        y = np.argmax(y, axis=1).astype(np.int)\n",
    "        y = torch.from_numpy(y)\n",
    "        return X, y\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_optimizer = optim.Adam(Q.parameters(), lr=lr)\n",
    "P_optimizer = optim.Adam(P.parameters(), lr=lr)\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: 1.476; G_loss: 0.5378; recon_loss: 0.6613\n",
      "Iter-1000; D_loss: 1.555; G_loss: 0.6024; recon_loss: 0.2733\n",
      "Iter-2000; D_loss: 1.542; G_loss: 0.5959; recon_loss: 0.2738\n",
      "Iter-3000; D_loss: 1.488; G_loss: 0.613; recon_loss: 0.2406\n",
      "Iter-4000; D_loss: 1.364; G_loss: 0.6926; recon_loss: 0.2085\n",
      "Iter-5000; D_loss: 1.382; G_loss: 0.6965; recon_loss: 0.1609\n",
      "Iter-6000; D_loss: 1.382; G_loss: 0.6987; recon_loss: 0.1823\n",
      "Iter-7000; D_loss: 1.386; G_loss: 0.6965; recon_loss: 0.1695\n",
      "Iter-8000; D_loss: 1.381; G_loss: 0.6829; recon_loss: 0.1506\n",
      "Iter-9000; D_loss: 1.384; G_loss: 0.7114; recon_loss: 0.1906\n",
      "Iter-10000; D_loss: 1.38; G_loss: 0.6991; recon_loss: 0.1721\n",
      "Iter-11000; D_loss: 1.389; G_loss: 0.6854; recon_loss: 0.1496\n",
      "Iter-12000; D_loss: 1.394; G_loss: 0.684; recon_loss: 0.157\n",
      "Iter-13000; D_loss: 1.39; G_loss: 0.6832; recon_loss: 0.166\n",
      "Iter-14000; D_loss: 1.393; G_loss: 0.6841; recon_loss: 0.174\n",
      "Iter-15000; D_loss: 1.391; G_loss: 0.6974; recon_loss: 0.147\n",
      "Iter-16000; D_loss: 1.406; G_loss: 0.6984; recon_loss: 0.1687\n",
      "Iter-17000; D_loss: 1.389; G_loss: 0.6881; recon_loss: 0.1719\n",
      "Iter-18000; D_loss: 1.389; G_loss: 0.6922; recon_loss: 0.1462\n",
      "Iter-19000; D_loss: 1.403; G_loss: 0.6846; recon_loss: 0.1574\n",
      "Iter-20000; D_loss: 1.389; G_loss: 0.6859; recon_loss: 0.1574\n",
      "Iter-21000; D_loss: 1.38; G_loss: 0.7023; recon_loss: 0.161\n",
      "Iter-22000; D_loss: 1.379; G_loss: 0.6923; recon_loss: 0.1661\n",
      "Iter-23000; D_loss: 1.385; G_loss: 0.6871; recon_loss: 0.1689\n",
      "Iter-24000; D_loss: 1.386; G_loss: 0.6973; recon_loss: 0.1558\n",
      "Iter-25000; D_loss: 1.401; G_loss: 0.7016; recon_loss: 0.1763\n",
      "Iter-26000; D_loss: 1.403; G_loss: 0.6884; recon_loss: 0.1572\n",
      "Iter-27000; D_loss: 1.387; G_loss: 0.6936; recon_loss: 0.1703\n",
      "Iter-28000; D_loss: 1.392; G_loss: 0.6964; recon_loss: 0.1649\n",
      "Iter-29000; D_loss: 1.385; G_loss: 0.6884; recon_loss: 0.1659\n",
      "Iter-30000; D_loss: 1.394; G_loss: 0.6841; recon_loss: 0.1738\n",
      "Iter-31000; D_loss: 1.396; G_loss: 0.6968; recon_loss: 0.1728\n",
      "Iter-32000; D_loss: 1.378; G_loss: 0.6984; recon_loss: 0.1745\n",
      "Iter-33000; D_loss: 1.396; G_loss: 0.6788; recon_loss: 0.1649\n",
      "Iter-34000; D_loss: 1.39; G_loss: 0.6928; recon_loss: 0.1646\n",
      "Iter-35000; D_loss: 1.381; G_loss: 0.695; recon_loss: 0.1503\n",
      "Iter-36000; D_loss: 1.388; G_loss: 0.7064; recon_loss: 0.1613\n",
      "Iter-37000; D_loss: 1.398; G_loss: 0.6825; recon_loss: 0.1663\n",
      "Iter-38000; D_loss: 1.397; G_loss: 0.6856; recon_loss: 0.1589\n",
      "Iter-39000; D_loss: 1.392; G_loss: 0.6816; recon_loss: 0.1569\n",
      "Iter-40000; D_loss: 1.388; G_loss: 0.7026; recon_loss: 0.1536\n",
      "Iter-41000; D_loss: 1.396; G_loss: 0.6833; recon_loss: 0.151\n",
      "Iter-42000; D_loss: 1.39; G_loss: 0.6891; recon_loss: 0.1426\n",
      "Iter-43000; D_loss: 1.389; G_loss: 0.7044; recon_loss: 0.1771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-191995d8d68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mQ_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mreset_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for it in range(1000000):\n",
    "    X = sample_X(mb_size)\n",
    "    \n",
    "    # reconstruction phase\n",
    "    z_sample = Q(X)\n",
    "    X_sample = P(z_sample)    \n",
    "    recon_loss = F.binary_cross_entropy(X_sample, X)\n",
    "    \n",
    "    recon_loss.backward()\n",
    "    P_optimizer.step()\n",
    "    Q_optimizer.step()\n",
    "    reset_grad()\n",
    "\n",
    "    # regularization phase\n",
    "    z_real = torch.randn(mb_size, z_dim)\n",
    "    z_fake = Q(X)\n",
    "    \n",
    "    D_real = D(z_real)\n",
    "    D_fake = D(z_fake)\n",
    "    \n",
    "    D_loss = - torch.mean(torch.log(D_real) + torch.log(1 - D_fake))\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "    reset_grad()\n",
    "    \n",
    "    # generator\n",
    "    z_fake = Q(X)\n",
    "    D_fake = D(z_fake)\n",
    "    G_loss = -torch.mean(torch.log(D_fake))\n",
    "    G_loss.backward()\n",
    "    Q_optimizer.step()\n",
    "    reset_grad()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {:.4}; G_loss: {:.4}; recon_loss: {:.4}'.format(it, D_loss.item(), G_loss.item(), recon_loss.item()))\n",
    "        samples = P(z_real).detach().numpy()[:16]\n",
    "        \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "        \n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "        \n",
    "        os.makedirs('aae', exist_ok=True)\n",
    "        plt.savefig('aae/{}.png'.format(str(cnt).zfill(3)), bbox_inches='tight')\n",
    "        cnt += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
